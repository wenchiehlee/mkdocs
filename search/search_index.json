{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AI","text":""},{"location":"#overview","title":"Overview","text":"Figure 1 Full AI vision"},{"location":"#donkey-car","title":"Donkey Car","text":""},{"location":"tag/","title":"Tags","text":"<p>Tip</p> <p>Below is Tag lists</p>"},{"location":"tag/#audio-synthesis","title":"Audio Synthesis","text":"<ul> <li>Data Trasmit Over Sound- Chimay Ultrasound</li> <li>Pytorch POC 5: Audio De-Noiser</li> </ul>"},{"location":"tag/#dataset","title":"Dataset","text":"<ul> <li>Dataset</li> </ul>"},{"location":"tag/#deep-learning","title":"Deep Learning","text":"<ul> <li>Deep Learning</li> </ul>"},{"location":"tag/#face-recognition","title":"Face Recognition","text":"<ul> <li>Tensorflow.js POC 7: face-api.js</li> <li>Tensorflow.js POC 12: Cam Face-recognition on face-api.js</li> <li>Tensorflow.js POC 13: Avatar Generator with Face-API.js</li> </ul>"},{"location":"tag/#fine-tune-model","title":"Fine-Tune Model","text":"<ul> <li>Pytorch POC 6: WIFI Indoor Positioning</li> <li>Tensorflow.js POC 13: Avatar Generator with Face-API.js</li> </ul>"},{"location":"tag/#image-feature-extraction","title":"Image Feature Extraction","text":"<ul> <li>Tensorflow.js POC 4: Facemesh</li> <li>Tensorflow.js POC 1: Pose-animator</li> <li>Tensorflow.js POC 6: Posenet</li> <li>Tensorflow.js POC 9: WhoIsTalking Based on Facemesh</li> <li>Tensorflow.js POC 13: Handpose and its potential POCs</li> </ul>"},{"location":"tag/#image-segmentation","title":"Image Segmentation","text":"<ul> <li>Tensorflow.js POC 3: body-pixv2</li> <li>U2Net</li> </ul>"},{"location":"tag/#image-to-image-transformer","title":"Image to Image Transformer","text":"<ul> <li>Max POC 2: Super Resolution with SRGAN</li> <li>Tensorflow.js POC 8: Super Resolution with waifu2x</li> <li>Tensorflow.js POC 8: Super Resolution with waifu2x (II)</li> </ul>"},{"location":"tag/#nlp","title":"NLP","text":"<ul> <li>Customer Feedback Tagging with NLP</li> <li>NLP- Word Understanding</li> </ul>"},{"location":"tag/#pre-trained-model","title":"Pre-trained Model","text":"<ul> <li>Tensorflow.js POC 3: body-pixv2</li> <li>Tensorflow.js POC 4: Facemesh</li> <li>Tensorflow.js POC 1: Pose-animator</li> <li>Tensorflow.js POC 6: Posenet</li> <li>Tensorflow.js POC 9: WhoIsTalking Based on Facemesh</li> <li>Max POC 2: Super Resolution with SRGAN</li> <li>Tensorflow.js POC 8: Super Resolution with waifu2x</li> <li>Tensorflow.js POC 8: Super Resolution with waifu2x (II)</li> <li>Tensorflow.js POC 7: face-api.js</li> <li>Pre-trained Model, and What is Next Steps</li> <li>Deep Learning Computing Architecture</li> <li>Tensorflow.js POC 12: Slim Based on Facemesh</li> <li>Tensorflow.js POC 10: Tochup Based on Facemesh</li> <li>Pytorch POC 2: OpenTTS</li> <li>Recommendation</li> <li>Tensorflow.js POC 12: Cam Face-recognition on face-api.js</li> <li>Pytorch POC 3: MozzilaTTS</li> <li>Tensorflow.js POC 13: Handpose and its potential POCs</li> <li>U2Net</li> <li>Pytorch POC 5: Audio De-Noiser</li> <li>Customer Feedback Tagging with NLP</li> </ul>"},{"location":"tag/#pytorch","title":"Pytorch","text":"<ul> <li>Pytorch POC 2: OpenTTS</li> <li>Recommendation</li> <li>Pytorch POC 3: MozzilaTTS</li> <li>U2Net</li> </ul>"},{"location":"tag/#recommendation","title":"Recommendation","text":"<ul> <li>Recommendation</li> </ul>"},{"location":"tag/#reinforcement-learning","title":"Reinforcement Learning","text":"<ul> <li>Supervised Learning vs. Semi-Supervised Learning vs. Reenforcement Learning</li> <li>Tensorflow.js POC 12: Cam Face-recognition on face-api.js</li> </ul>"},{"location":"tag/#semi-supervised-learning","title":"Semi-Supervised Learning","text":"<ul> <li>Tensorflow.js POC 7: face-api.js</li> <li>Supervised Learning vs. Semi-Supervised Learning vs. Reenforcement Learning</li> <li>Tensorflow.js POC 13: Handpose and its potential POCs</li> <li>Customer Feedback Tagging with NLP</li> </ul>"},{"location":"tag/#speech-synthesis","title":"Speech Synthesis","text":"<ul> <li>Pytorch POC 2: OpenTTS</li> <li>Pytorch POC 3: MozzilaTTS</li> </ul>"},{"location":"tag/#supervised-learning","title":"Supervised Learning","text":"<ul> <li>Tensorflow.js POC 3: body-pixv2</li> <li>Tensorflow.js POC 4: Facemesh</li> <li>Tensorflow.js POC 1: Pose-animator</li> <li>Tensorflow.js POC 6: Posenet</li> <li>Tensorflow.js POC 9: WhoIsTalking Based on Facemesh</li> <li>Supervised Learning vs. Semi-Supervised Learning vs. Reenforcement Learning</li> <li>Pytorch POC 2: OpenTTS</li> <li>Recommendation</li> <li>Pytorch POC 3: MozzilaTTS</li> <li>U2Net</li> <li>Pytorch POC 5: Audio De-Noiser</li> <li>Pytorch POC 6: WIFI Indoor Positioning</li> <li>Tensorflow.js POC 13: Avatar Generator with Face-API.js</li> </ul>"},{"location":"tag/#synology","title":"Synology","text":"<ul> <li>Github runner in Synology NAS</li> </ul>"},{"location":"tag/#tensorflow","title":"Tensorflow","text":"<ul> <li>Tensorflow.js POC 3: body-pixv2</li> <li>Tensorflow.js POC 4: Facemesh</li> <li>Tensorflow.js POC 1: Pose-animator</li> <li>Tensorflow.js POC 6: Posenet</li> <li>Tensorflow.js POC 9: WhoIsTalking Based on Facemesh</li> <li>Tensorflow.js POC 8: Super Resolution with waifu2x</li> <li>Tensorflow.js POC 8: Super Resolution with waifu2x (II)</li> <li>Tensorflow.js POC 7: face-api.js</li> <li>Tensorflow.js POC 12: Cam Face-recognition on face-api.js</li> <li>Tensorflow.js POC 13: Handpose and its potential POCs</li> <li>Pytorch POC 5: Audio De-Noiser</li> <li>Pytorch POC 6: WIFI Indoor Positioning</li> <li>Tensorflow.js POC 13: Avatar Generator with Face-API.js</li> </ul>"},{"location":"tag/#unsupervised-learning","title":"Unsupervised Learning","text":"<ul> <li>Supervised Learning vs. Semi-Supervised Learning vs. Reenforcement Learning</li> </ul>"},{"location":"tag/#wifi-indoor-positioning","title":"WIFI Indoor Positioning","text":"<ul> <li>Pytorch POC 6: WIFI Indoor Positioning</li> </ul>"},{"location":"tag/#featured","title":"featured","text":"<ul> <li>High Availablity Deployment</li> </ul>"},{"location":"about/","title":"About the teams","text":"<p>Wen-Chieh Lee</p><p>Senior Software Architect</p> <p>Andy Lee</p><p>AI Developer</p> <p>Kohsin Lee</p><p>Software/AI Developer</p>"},{"location":"about/#timeline","title":"Timeline","text":"<p>start</p> 2024-11<p>Web site launch</p> <p>starting</p> 2024-12<p>First blog</p>"},{"location":"about/#credits","title":"Credits","text":"<p>This web built based on the helps below.</p> <p>Mkdocs for Materials</p><p>Documentation that simply works</p> <p>Wcowin's Web</p><p>\u5faa\u6b64\u82e6\u65c5\uff0c\u4ee5\u9054\u661f\u8fb0</p> <p>neoteroi-mkdocs</p><p>Plugins for MkDocs</p>"},{"location":"about/link/","title":"\u53cb\u93c8","text":"<p>Wen-Chieh Lee</p><p>Works related stuffs</p> <p>Wen-Chieh Lee\u7684\u751f\u6d3b</p><p>\u7a2e\u690d, \u990a\u6b96, \u91c0</p> <p>Wen-Chieh Lee\u7684\u6295\u8cc7\u5806\u758a</p><p>\u7528\u65bc\u7ba1\u7406\u6295\u8cc7\u7684\u5206\u5c64\u67b6\u69cb\u6216\u65b9\u6cd5..</p> <p>wenchiehlee.synology.me</p><p>Techs related stuffs to Synology NAS</p>"},{"location":"about/link/#useful-links","title":"Useful Links","text":"<p>Zeus</p><p>Lorem ipsum dolor sit amet.</p> <p>Athena</p> <p>Lorem ipsum dolor sit amet.</p> <p>Poseidon</p> <p>Lorem ipsum dolor sit amet.</p> <p>Artemis</p> <p>Lorem ipsum dolor sit amet.</p> <p>Ares</p> <p>Lorem ipsum dolor sit amet.</p> <p>Nike</p> <p>Lorem ipsum dolor sit amet.</p> <p>60fps</p> <p>Lorem ipsum dolor sit amet.</p> <p>4G</p> <p>Lorem ipsum dolor sit amet.</p>"},{"location":"blog/","title":"Blogs","text":""},{"location":"blog/2020/06/tensorflowjs-poc-3-body-pixv2/","title":"Tensorflow.js POC 3: body-pixv2","text":"","tags":["Tensorflow","Pre-trained Model","Image Segmentation","Supervised Learning"]},{"location":"blog/2020/06/tensorflowjs-poc-3-body-pixv2/#overview","title":"Overview","text":"Figure 1 Computer Vision in AI Git Repo Status Progress Comments tensorflow.js POC #3","tags":["Tensorflow","Pre-trained Model","Image Segmentation","Supervised Learning"]},{"location":"blog/2020/06/tensorflowjs-poc-4-facemesh/","title":"Tensorflow.js POC 4: Facemesh","text":"","tags":["Tensorflow","Pre-trained Model","Image Feature Extraction","Supervised Learning"]},{"location":"blog/2020/06/tensorflowjs-poc-4-facemesh/#overview","title":"Overview","text":"Figure 1 Computer Vision in AI Git Repo Status Progress Comments tensorflow.js POC #4","tags":["Tensorflow","Pre-trained Model","Image Feature Extraction","Supervised Learning"]},{"location":"blog/2020/06/tensorflowjs-poc-1-pose-animator/","title":"Tensorflow.js POC 1: Pose-animator","text":"Figure 1 Computer Vision in AI Git Repo Status Progress Comments tensorflow.js POC #1- and WhoIsTalking for PIC #9.","tags":["Tensorflow","Pre-trained Model","Image Feature Extraction","Supervised Learning"]},{"location":"blog/2020/06/tensorflowjs-poc-1-pose-animator/#demo","title":"Demo","text":"<p>A demo for two people for pose-animators. Since pose-estmiation and facemesh are not correctly aligned so sometimes, face and body will be mis-aligned. So next step for pose-animator is to improve the pose-estmiation and facemesh alignment for multiple users.</p> <p></p>","tags":["Tensorflow","Pre-trained Model","Image Feature Extraction","Supervised Learning"]},{"location":"blog/2020/06/tensorflowjs-poc-1-pose-animator/#next-milestone","title":"Next Milestone","text":"<ol> <li>To support pose-estmiation and facemesh alignment for multiple users</li> </ol>","tags":["Tensorflow","Pre-trained Model","Image Feature Extraction","Supervised Learning"]},{"location":"blog/2020/06/tensorflowjs-poc-6-posenet/","title":"Tensorflow.js POC 6: Posenet","text":"Figure 1 Computer Vision in AI Git Repo Status Progress Comments tensorflow.js POC #6","tags":["Tensorflow","Pre-trained Model","Image Feature Extraction","Supervised Learning"]},{"location":"blog/2020/06/tensorflowjs-poc-6-posenet/#references","title":"References","text":"<ul> <li>The Top 57 Human Pose Estimation Open Source Projects</li> <li>\u4f7f\u7528\u795e\u7d93\u7db2\u7d61\u9032\u884c\u5c0d\u8c61\u6aa2\u6e2c\u2014\u2014\u4f7f\u7528 keras \u7684\u7c21\u55ae\u6559\u7a0b</li> </ul>","tags":["Tensorflow","Pre-trained Model","Image Feature Extraction","Supervised Learning"]},{"location":"blog/2020/06/tensorflowjs-poc-9-whoistalking-based-on-facemesh/","title":"Tensorflow.js POC 9: WhoIsTalking Based on Facemesh","text":"","tags":["Tensorflow","Pre-trained Model","Image Feature Extraction","Supervised Learning"]},{"location":"blog/2020/06/tensorflowjs-poc-9-whoistalking-based-on-facemesh/#overview","title":"Overview","text":"<p> Figure 1 Computer Vision in AI</p> Git Repo Status Progress Comments tensorflow.js POC #1- and WhoIsTalking for PIC #9. <p></p> <p>Based on tensorflow pre-trained model- facemesh, to POC Who is talking to show multiple users talking or not detection. </p>","tags":["Tensorflow","Pre-trained Model","Image Feature Extraction","Supervised Learning"]},{"location":"blog/2020/06/max-poc-2-super-resolution-with-srgan/","title":"Max POC 2: Super Resolution with SRGAN","text":"","tags":["Pre-trained Model","Image to Image Transformer"]},{"location":"blog/2020/06/max-poc-2-super-resolution-with-srgan/#overview","title":"Overview","text":"Figure 1 Computer Vision in AI Git Repo Status Progress Comments IBM MAX SRGAN POC #2 <p>The above image is one result of SRGAN. It is not good in artwork image. Visit the online benchmark comparsion of SRGAN of several different images on POC: Super Resolution with waifu2x</p>","tags":["Pre-trained Model","Image to Image Transformer"]},{"location":"blog/2020/06/max-poc-2-super-resolution-with-srgan/#references","title":"References","text":"<ul> <li>Play with Generative Adversarial Networks (GANs) in your browser!</li> <li>ECCV 2020 | \u5982\u4f55\u6062\u590d\u964d\u91c7\u6837\u540e\u7684\u9ad8\u6e05\u56fe\u7247\uff1f\u53ef\u9006\u56fe\u50cf\u7f29\u653e\u641e\u5b9a</li> </ul>","tags":["Pre-trained Model","Image to Image Transformer"]},{"location":"blog/2020/06/tensorflowjs-poc-8-super-resolution-with-waifu2x/","title":"Tensorflow.js POC 8: Super Resolution with waifu2x","text":"","tags":["Tensorflow","Pre-trained Model","Image to Image Transformer"]},{"location":"blog/2020/06/tensorflowjs-poc-8-super-resolution-with-waifu2x/#overview","title":"Overview","text":"Figure 1 Computer Vision in AI <pre><code>&lt;body&gt;\n    &lt;script src=\"https://code.jquery.com/jquery-3.3.1.min.js\" integrity=\"sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=\" crossorigin=\"anonymous\"&gt;&lt;/script&gt;\n\n    &lt;script src=\"../../assets/plugins/jquery.event.move.js\"&gt;&lt;/script&gt;\n    &lt;script src=\"../../assets/plugins/jquery.twentytwenty.js\"&gt;&lt;/script&gt;\n    &lt;script&gt;\n      $(function()\n      {\n\n        $(\".twentytwenty-container\").eq(0).twentytwenty({default_offset_pct: 0.5,before_label: 'bicubic',after_label: 'waifu2x',click_to_move: true});\n        $(\".twentytwenty-container\").eq(1).twentytwenty({default_offset_pct: 0.5,before_label: 'lanczos3',after_label: 'waifu2x',click_to_move: true});\n        $(\".twentytwenty-container\").eq(2).twentytwenty({default_offset_pct: 0.5,before_label: 'SRGAN',after_label: 'waifu2x-NCNN',click_to_move: true});\n        $(\".twentytwenty-container\").eq(3).twentytwenty({default_offset_pct: 0.5,before_label: 'waifu2x',after_label: 'waifu2x-NCNN',click_to_move: true});\n        $(\".twentytwenty-container\").eq(4).twentytwenty({default_offset_pct: 0.5,before_label: 'waifu2x',after_label: 'SRMD-NCNN',click_to_move: true});\n        $(\".twentytwenty-container\").eq(5).twentytwenty({default_offset_pct: 0.5,before_label: 'waifu2x',after_label: 'Anime4K',click_to_move: true});\n        $(\".twentytwenty-container\").eq(6).twentytwenty({default_offset_pct: 0.5,before_label: 'bicubic',after_label: 'Anime4K',click_to_move: true});\n\n        $(\".twentytwenty-container\").eq(7).twentytwenty({default_offset_pct: 0.5,before_label: 'bicubic',after_label: 'waifu2x_artwork',click_to_move: true});\n        $(\".twentytwenty-container\").eq(8).twentytwenty({default_offset_pct: 0.5,before_label: 'lanczos3',after_label: 'waifu2x_artwork',click_to_move: true});\n        $(\".twentytwenty-container\").eq(9).twentytwenty({default_offset_pct: 0.5,before_label: 'waifu2x_artwork',after_label: 'waifu2x_artwork_y',click_to_move: true});\n        $(\".twentytwenty-container\").eq(10).twentytwenty({default_offset_pct: 0.5,before_label: 'waifu2x_artwork',after_label: 'waifu2x_photo',click_to_move: true});\n\n        $(\".twentytwenty-container\").eq(11).twentytwenty({default_offset_pct: 0.5,before_label: 'bicubic',after_label: 'lanczos3',click_to_move: true});\n        $(\".twentytwenty-container\").eq(12).twentytwenty({default_offset_pct: 0.5,before_label: 'waifu2x_artwork',after_label: 'lanczos3',click_to_move: true});\n        $(\".twentytwenty-container\").eq(13).twentytwenty({default_offset_pct: 0.5,before_label: 'waifu2x_artwork',after_label: 'waifu2x_photo',click_to_move: true});\n        $(\".twentytwenty-container\").eq(14).twentytwenty({default_offset_pct: 0.5,before_label: 'waifu2x_artwork',after_label: 'waifu2x_artwork_y',click_to_move: true});\n        $(\".twentytwenty-container\").eq(15).twentytwenty({default_offset_pct: 0.5,before_label: 'lanczos3',after_label: 'waifu2x_photo',click_to_move: true});\n      });\n    &lt;/script&gt;\n&lt;/body&gt;\n</code></pre> Git Repo Status Progress Comments tensorflow.js POC #8","tags":["Tensorflow","Pre-trained Model","Image to Image Transformer"]},{"location":"blog/2020/06/tensorflowjs-poc-8-super-resolution-with-waifu2x/#overview_1","title":"Overview","text":"<p>Super Resolution of images are important for video quality. Common SR like bicubic or lanczos3, now embedded in GPU as default SR. But, in 4K display or larger display, common SR is not enough, SR with Deep learning provide significant improvements on differnt target images. </p> <p>Super resolution of images highly depends the properties of the image, like animation, line draw, or a full color complex nature images will have different results on different algorithms. Here we benchmark several traditional SR algorithm of bicubic, lanczos3, (Bell, and ....) from imageenlarger and do a comparison with a DL SR on line draw or animation style image. </p> <p>Now we provide A/B Test on the different target images to verify the results of deep learning and normal images.</p>","tags":["Tensorflow","Pre-trained Model","Image to Image Transformer"]},{"location":"blog/2020/06/tensorflowjs-poc-8-super-resolution-with-waifu2x/#ab-test-on-waifu2x-ncnn-vs-waifu2x-vs-lanczos3-vs-bicubic-vs-srgan","title":"A/B test on waifu2x-NCNN vs. waifu2x vs. lanczos3 vs. bicubic vs. SRGAN","text":"","tags":["Tensorflow","Pre-trained Model","Image to Image Transformer"]},{"location":"blog/2020/06/tensorflowjs-poc-8-super-resolution-with-waifu2x/#1096x632_ppt_image","title":"1096x632_PPT_image","text":"<p>1096x632_PPT_image is a 1096x632 size PNG with words and graph PPT. We use it to identify the clearance of the SR.</p> <p>SRMD-NCNN = waifu2x-NCNN = waifu2x &gt; lanczos3 &gt; bicubic &gt; Anime4K &gt; SRGAN (bicubic is most GPU interpolation algorithm. So lanczos3 and waifu2x show better results to normal GPU). SRGAN, Anime4K: SR result is GG..</p>","tags":["Tensorflow","Pre-trained Model","Image to Image Transformer"]},{"location":"blog/2020/06/tensorflowjs-poc-8-super-resolution-with-waifu2x/#quality-comparison-bicubic-waifu2x","title":"Quality comparison: bicubic &lt; waifu2x","text":"<pre><code>{% slider2020 %}\n  ![bicubic](../../assets/images/1096x632_PPT_image-bicubic.png)\n  ![waifu2x](../../assets/images/1096x632_PPT_image_waifu2x_art_noise1_scale_tta_1.png)\n{% endslider2020 %}\n\n#### Quality comparison: lanczos3 &lt; waifu2x\n{% slider2020 %}\n  ![lanczos3](../../assets/images/1096x632_PPT_image-lanczos3.png)\n  ![waifu2x](../../assets/images/1096x632_PPT_image_waifu2x_art_noise1_scale_tta_1.png)\n{% endslider2020 %}\n\n#### Quality comparison: SRGAN &lt; waifu2x. \nSRGAN is GG\n\n{% slider2020 %}\n  ![SRGAN](../../assets/images/1096x632_PPT_image-SRGAN.png)\n  ![waifu2x-NCNN](../../assets/images/1096x632_PPT_image_Waifu2x-NCNN-Vulkan.png)\n{% endslider2020 %}\n\n#### Quality comparison: waifu2x = waifu2x-NCNN\n\n{% slider2020 %}\n  ![waifu2x](../../assets/images/1096x632_PPT_image_waifu2x_art_noise1_scale_tta_1.png)\n  ![waifu2x-NCNN](../../assets/images/1096x632_PPT_image_Waifu2x-NCNN-Vulkan.png)\n{% endslider2020 %}\n\n#### Quality comparison: waifu2x = SRMD-NCNN\n\n{% slider2020 %}\n  ![waifu2x](../../assets/images/1096x632_PPT_image_waifu2x_art_noise1_scale_tta_1.png)\n  ![SRMD-NCNN](../../assets/images/1096x632_PPT_image_SRMD-NCNN-Vulkan.png)\n{% endslider2020 %}\n\n\n#### Quality comparison: waifu2x &gt; Anime4K\n\n{% slider2020 %}\n  ![waifu2x](../../assets/images/1096x632_PPT_image_waifu2x_art_noise1_scale_tta_1.png)\n  ![Anime4K](../../assets/images/1096x632_PPT_image_Anime4K.png)\n{% endslider2020 %}\n\n#### Quality comparison: bicubic &gt; Anime4K\n\n{% slider2020 %}\n  ![bicubic](../../assets/images/1096x632_PPT_image-bicubic.png)\n  ![Anime4K](../../assets/images/1096x632_PPT_image_Anime4K.png)\n{% endslider2020 %}\n</code></pre>","tags":["Tensorflow","Pre-trained Model","Image to Image Transformer"]},{"location":"blog/2020/06/tensorflowjs-poc-8-super-resolution-with-waifu2x/#part-ii","title":"Part II","text":"<p>Check Part II</p>","tags":["Tensorflow","Pre-trained Model","Image to Image Transformer"]},{"location":"blog/2020/06/tensorflowjs-poc-8-super-resolution-with-waifu2x/#next-step","title":"Next step","text":"<ul> <li>WenGL version of waifu2x.js</li> <li>Speedup of waifu2x</li> </ul>","tags":["Tensorflow","Pre-trained Model","Image to Image Transformer"]},{"location":"blog/2020/06/tensorflowjs-poc-8-super-resolution-with-waifu2x/#references","title":"References","text":"<ul> <li>waifu2x tensorflow c++ repo</li> <li>waifu2x tensorflow.js repo</li> </ul>","tags":["Tensorflow","Pre-trained Model","Image to Image Transformer"]},{"location":"blog/2020/06/tensorflowjs-poc-8-super-resolution-with-waifu2x/#jekyll-image-comparison-slider","title":"Jekyll image comparison slider","text":"<p>In this page, twentytwenty image compare slider is used to enable image comparison slider.</p> <p>To enable it in your post, please add the following code into your markdown documents</p> <pre><code>{% slider2020 %}\n  ![lanczos3](../../assets/images/1096x632_PPT_image-lanczos3.png)\n  ![Waifu2x](../../assets/images/1096x632_PPT_image_Waifu2x-NCNN-Vulkan.png)\n{% endslider2020 %}\n</code></pre> <p>After above, you can have first version of image compariosn slider. But, if you want to change the label of the images. you will need to find default_with_image_slider.html and modify the code as below in the beginning of the .md file</p> <pre><code>&lt;body&gt;\n    &lt;script src=\"https://code.jquery.com/jquery-3.3.1.min.js\" integrity=\"sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=\" crossorigin=\"anonymous\"&gt;&lt;/script&gt;\n\n    &lt;script src=\"../../assets/plugins/jquery.event.move.js\"&gt;&lt;/script&gt;\n    &lt;script src=\"../../assets/plugins/jquery.twentytwenty.js\"&gt;&lt;/script&gt;\n    &lt;script&gt;\n      $(function()\n      {\n\n        $(\".twentytwenty-container\").eq(0).twentytwenty({default_offset_pct: 0.5,before_label: 'lanczos3',after_label: 'waifu2x-NCNN',click_to_move: true});\n      });\n    &lt;/script&gt;\n&lt;/body&gt;\n</code></pre> <p>You also can check the code of this site in gitbucket and search for all 'twentytwenty'</p>","tags":["Tensorflow","Pre-trained Model","Image to Image Transformer"]},{"location":"blog/2020/06/tensorflowjs-poc-8-super-resolution-with-waifu2x-ii/","title":"Tensorflow.js POC 8: Super Resolution with waifu2x (II)","text":"","tags":["Tensorflow","Pre-trained Model","Image to Image Transformer"]},{"location":"blog/2020/06/tensorflowjs-poc-8-super-resolution-with-waifu2x-ii/#overview","title":"Overview","text":"Figure 1 Computer Vision in AI <pre><code>&lt;body&gt;\n    &lt;script src=\"https://code.jquery.com/jquery-3.3.1.min.js\" integrity=\"sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=\" crossorigin=\"anonymous\"&gt;&lt;/script&gt;\n\n    &lt;script src=\"../../assets/plugins/jquery.event.move.js\"&gt;&lt;/script&gt;\n    &lt;script src=\"../../assets/plugins/jquery.twentytwenty.js\"&gt;&lt;/script&gt;\n    &lt;script&gt;\n      $(function()\n      {\n\n        $(\".twentytwenty-container\").eq(0).twentytwenty({default_offset_pct: 0.5,before_label: 'bicubic',after_label: 'waifu2x_artwork',click_to_move: true});\n        $(\".twentytwenty-container\").eq(1).twentytwenty({default_offset_pct: 0.5,before_label: 'lanczos3',after_label: 'waifu2x_artwork',click_to_move: true});\n        $(\".twentytwenty-container\").eq(2).twentytwenty({default_offset_pct: 0.5,before_label: 'waifu2x_artwork',after_label: 'waifu2x_artwork_y',click_to_move: true});\n        $(\".twentytwenty-container\").eq(3).twentytwenty({default_offset_pct: 0.5,before_label: 'waifu2x_artwork',after_label: 'waifu2x_photo',click_to_move: true});\n\n        $(\".twentytwenty-container\").eq(4).twentytwenty({default_offset_pct: 0.5,before_label: 'bicubic',after_label: 'lanczos3',click_to_move: true});\n        $(\".twentytwenty-container\").eq(5).twentytwenty({default_offset_pct: 0.5,before_label: 'waifu2x_artwork',after_label: 'lanczos3',click_to_move: true});\n        $(\".twentytwenty-container\").eq(6).twentytwenty({default_offset_pct: 0.5,before_label: 'waifu2x_artwork',after_label: 'waifu2x_photo',click_to_move: true});\n        $(\".twentytwenty-container\").eq(7).twentytwenty({default_offset_pct: 0.5,before_label: 'waifu2x_artwork',after_label: 'waifu2x_artwork_y',click_to_move: true});\n        $(\".twentytwenty-container\").eq(8).twentytwenty({default_offset_pct: 0.5,before_label: 'lanczos3',after_label: 'waifu2x_artwork',click_to_move: true});\n        $(\".twentytwenty-container\").eq(9).twentytwenty({default_offset_pct: 0.5,before_label: 'waifu2x_artwork',after_label: 'waifu2x_artwork_y',click_to_move: true});\n        $(\".twentytwenty-container\").eq(10).twentytwenty({default_offset_pct: 0.5,before_label: 'lanczos3',after_label: 'waifu2x_photo',click_to_move: true});\n\n      });\n    &lt;/script&gt;\n&lt;/body&gt;\n</code></pre> Git Repo Status Progress Comments tensorflow.js POC #8","tags":["Tensorflow","Pre-trained Model","Image to Image Transformer"]},{"location":"blog/2020/06/tensorflowjs-poc-8-super-resolution-with-waifu2x-ii/#avatar255x287","title":"avatar255x287","text":"<p>avatar255x287 is a 255x287 size PNG animation. We use it to identify the aliasing reduction of the SR.</p> <p>waifu2x-photo = waifu2x-artwork_y = waifu2x-artwork &gt; lanczos3 &gt; bicubic</p>","tags":["Tensorflow","Pre-trained Model","Image to Image Transformer"]},{"location":"blog/2020/06/tensorflowjs-poc-8-super-resolution-with-waifu2x-ii/#quality-comparison-bicubic-waifu2x_artwork","title":"Quality comparison: bicubic &lt; waifu2x_artwork","text":"<pre><code>{% slider2020 %}\n  ![bicubic](../../assets/images/avatar255x287-bicubic.png)\n  ![waifu2x_artwork](../../assets/images/avatar255x287-waifu2x_artwork.png)\n{% endslider2020 %}\n\n#### Quality comparison: lanczos3 &lt; waifu2x_artwork\n{% slider2020 %}\n  ![lanczos3](../../assets/images/avatar255x287-lanczos3.png)\n  ![waifu2x_artwork](../../assets/images/avatar255x287-waifu2x_artwork.png)\n{% endslider2020 %}\n\n#### Quality comparison: waifu2x_artwork = waifu2x_artwork_y\n\n{% slider2020 %}\n  ![waifu2x_artwork](../../assets/images/avatar255x287-waifu2x_artwork.png)\n  ![waifu2x_artwork_y](../../assets/images/avatar255x287-waifu2x_artwork_y.png)\n{% endslider2020 %}\n\n#### Quality comparison: waifu2x_artwork = waifu2x_photo\n\n{% slider2020 %}\n  ![waifu2x_artwork](../../assets/images/avatar255x287-waifu2x_artwork.png)\n  ![waifu2x_photo](../../assets/images/avatar255x287-waifu2x_photo.png)\n{% endslider2020 %}\n\n### lena400x400\n\nlena400x400 is a 400x400 size JPG with natural human. We use it to identify the color richness and fine struture of the SR.\n\n waifu2x-artwork_y = waifu2x-artwork &gt; waifu2x-photo &gt; lanczos3 = bicubic\n\n#### Quality comparison: bicubic = lanczos3\n\n{% slider2020 %}\n  ![bicubic](../../assets/images/lena400x400-bicubic.png)\n  ![lanczos3](../../assets/images/lena400x400-lanczos3.png)\n{% endslider2020 %}\n\n#### Quality comparison: waifu2x_artwork &gt; lanczos3\n\n{% slider2020 %}\n  ![waifu2x_artwork](../../assets/images/lena400x400-waifu2x_artwork.png)\n  ![lanczos3](../../assets/images/lena400x400-lanczos3.png)\n{% endslider2020 %}\n\n#### Quality comparison: waifu2x_artwork &gt; waifu2x_photo\n\n{% slider2020 %}\n  ![waifu2x_artwork](../../assets/images/lena400x400-waifu2x_artwork.png)\n  ![lanczos3](../../assets/images/lena400x400-waifu2x_photo.png)\n{% endslider2020 %}\n\n#### Quality comparison: waifu2x_artwork = waifu2x_artwork_y\n\n{% slider2020 %}\n  ![waifu2x_artwork](../../assets/images/lena400x400-waifu2x_artwork.png)\n  ![waifu2x_artwork_y](../../assets/images/lena400x400-waifu2x_artwork_y.png)\n{% endslider2020 %}\n\n#### Quality comparison: lanczos3 &lt; waifu2x_photo\n\n{% slider2020 %}\n  ![lanczos3](../../assets/images/lena400x400-lanczos3.png)\n  ![waifu2x_photo](../../assets/images/lena400x400-waifu2x_photo.png)\n{% endslider2020 %}\n</code></pre>","tags":["Tensorflow","Pre-trained Model","Image to Image Transformer"]},{"location":"blog/2020/06/tensorflowjs-poc-8-super-resolution-with-waifu2x-ii/#next-step","title":"Next step","text":"<ul> <li>WenGL version of waifu2x.js</li> </ul>","tags":["Tensorflow","Pre-trained Model","Image to Image Transformer"]},{"location":"blog/2020/06/tensorflowjs-poc-7-face-apijs/","title":"Tensorflow.js POC 7: face-api.js","text":"","tags":["Tensorflow","Pre-trained Model","Face Recognition","Semi-Supervised Learning"]},{"location":"blog/2020/06/tensorflowjs-poc-7-face-apijs/#overview","title":"Overview","text":"<p> Figure 1 Computer Vision in AI</p>","tags":["Tensorflow","Pre-trained Model","Face Recognition","Semi-Supervised Learning"]},{"location":"blog/2020/06/tensorflowjs-poc-7-face-apijs/#project-status","title":"Project Status","text":"Git Repo Status Progress Comments tensorflow.js POC #7","tags":["Tensorflow","Pre-trained Model","Face Recognition","Semi-Supervised Learning"]},{"location":"blog/2020/06/tensorflowjs-poc-7-face-apijs/#project-map-of-dlc","title":"Project map of  DLC","text":"<p>Check the project in the project map of deep learning computing to see the whole picture.</p> <p> </p>","tags":["Tensorflow","Pre-trained Model","Face Recognition","Semi-Supervised Learning"]},{"location":"blog/2020/06/tensorflowjs-poc-7-face-apijs/#test-1","title":"Test #1","text":"","tags":["Tensorflow","Pre-trained Model","Face Recognition","Semi-Supervised Learning"]},{"location":"blog/2020/06/tensorflowjs-poc-7-face-apijs/#reference-input","title":"Reference Input","text":"<p>Step 1: Input reference image </p> <p>Step 2: extract faces and output face descriptors (Biometrics information of faces, 120 vectors value)  </p>","tags":["Tensorflow","Pre-trained Model","Face Recognition","Semi-Supervised Learning"]},{"location":"blog/2020/06/tensorflowjs-poc-7-face-apijs/#query-input","title":"Query Input","text":"<p>Step 1: Input query image </p> <p>Step 2: extract faces and output query face descriptors  </p> <p>Step 3: Compare reference and query face descriptors and output similarity score</p> <p>red block is missing faces.</p>","tags":["Tensorflow","Pre-trained Model","Face Recognition","Semi-Supervised Learning"]},{"location":"blog/2020/06/tensorflowjs-poc-7-face-apijs/#test-2","title":"Test #2","text":"","tags":["Tensorflow","Pre-trained Model","Face Recognition","Semi-Supervised Learning"]},{"location":"blog/2020/06/tensorflowjs-poc-7-face-apijs/#reference-input_1","title":"Reference Input","text":"","tags":["Tensorflow","Pre-trained Model","Face Recognition","Semi-Supervised Learning"]},{"location":"blog/2020/06/tensorflowjs-poc-7-face-apijs/#query-input_1","title":"Query Input","text":"<p>red block is missing faces.</p> <p></p>","tags":["Tensorflow","Pre-trained Model","Face Recognition","Semi-Supervised Learning"]},{"location":"blog/2020/06/tensorflowjs-poc-7-face-apijs/#references","title":"References","text":"<ul> <li>NBA Later 2014 team photo shot video</li> <li>\u8fd1\u4e09\u5e74\u81c9\u90e8\u8b58\u5225\u9802\u6703\u8ad6\u6587lists(\u66f4\u65b0\u4e2d...)</li> </ul>","tags":["Tensorflow","Pre-trained Model","Face Recognition","Semi-Supervised Learning"]},{"location":"blog/2020/07/pre-trained-model-and-what-is-next-steps/","title":"Pre-trained Model, and What is Next Steps","text":"","tags":["Pre-trained Model"]},{"location":"blog/2020/07/pre-trained-model-and-what-is-next-steps/#pre-trained-model","title":"Pre-trained Model","text":"<p>Pre-trained model for deep learning is the easiest entry point for an application developers to start the deep learning. With the pre-trained model as a blackbox, the application developers can focus on the problem he want to resolve with the pre-trained model and do the first integration and see the result of the integration resolve the target problem or not and how far it is to the perfect goal. If the goal become nearer, then a fine-tuning of pre-trained model or even a from-scratch pre-trained model can be addressed as a solution for the final integration.</p> <p>There are several pre-trained models based on different programming langnauges and platforms.</p>","tags":["Pre-trained Model"]},{"location":"blog/2020/07/pre-trained-model-and-what-is-next-steps/#tensorflowjs-pre-trained-models","title":"Tensorflow.js Pre-trained Models","text":"<ul> <li>Pre-trained model mirror from google</li> <li>npm tensorflow pre-train model</li> </ul>","tags":["Pre-trained Model"]},{"location":"blog/2020/07/pre-trained-model-and-what-is-next-steps/#ibm-max-pre-trained-models","title":"IBM MAX Pre-trained Models","text":"<ul> <li>Pre-trained model from IBM</li> </ul>","tags":["Pre-trained Model"]},{"location":"blog/2020/07/pre-trained-model-and-what-is-next-steps/#nvidia-pre-trained-models","title":"nVidia Pre-trained Models","text":"<ul> <li>NVIDIA Deep Learning Examples for Tensor Cores</li> </ul>","tags":["Pre-trained Model"]},{"location":"blog/2020/07/pre-trained-model-and-what-is-next-steps/#pytorch-pre-trained-models","title":"Pytorch Pre-trained Models","text":"","tags":["Pre-trained Model"]},{"location":"blog/2020/07/pre-trained-model-and-what-is-next-steps/#fine-tune-models","title":"Fine-tune Models","text":"<p>Once the pre-trained model gives some promise on the solution to the problem. A deeper and better solution can be addressed by fine-tuning the model. We call it as fine-tuning model of pre-trained model.</p> <p>There are several strategies of fine-tuning the models from much training efforts to less ones.</p> <p></p> <p>Another view for different dataset size for fine-tining models.</p> <p></p>","tags":["Pre-trained Model"]},{"location":"blog/2020/07/pre-trained-model-and-what-is-next-steps/#mlops","title":"MLOps","text":"<p>Main idea of whole ML pipeline. </p> <p></p> <p>Basic idea of MLOps pipeline.</p> <p></p>","tags":["Pre-trained Model"]},{"location":"blog/2020/07/pre-trained-model-and-what-is-next-steps/#references","title":"References","text":"<ul> <li>Pre-Trained Machine Learning Models vs Models Trained from Scratch</li> <li>Why Not Training Model From Scratch ?</li> <li>\u7d66ML Engineer\u7684MLOps\u7c21\u8ff0: \u6301\u7e8c\u958b\u767c\u6a5f\u5668\u5b78\u7fd2Service\u7684\u9ad8\u6548\u7406\u5ff5</li> <li>The Fundamentals Of MLOps \u2013 The Enabler Of Quality Outcomes In Production Environments</li> <li>AI\u2019s Biggest Struggle Yet \u2014 No Streamlined MLOps as a Service</li> </ul>","tags":["Pre-trained Model"]},{"location":"blog/2020/07/deep-learning-computing-architecture/","title":"Deep Learning Computing Architecture","text":"","tags":["Pre-trained Model"]},{"location":"blog/2020/07/deep-learning-computing-architecture/#current-deepl-learning-framework","title":"Current Deepl Learning Framework","text":"","tags":["Pre-trained Model"]},{"location":"blog/2020/07/deep-learning-computing-architecture/#diagram-of-tensorflow-20","title":"Diagram of Tensorflow 2.0","text":"","tags":["Pre-trained Model"]},{"location":"blog/2020/07/deep-learning-computing-architecture/#different-app-endpoints","title":"Different APP endpoints","text":"","tags":["Pre-trained Model"]},{"location":"blog/2020/07/deep-learning-computing-architecture/#diagram-of-pytorch","title":"Diagram of Pytorch","text":"<p>https://aws.amazon.com/blogs/machine-learning/deploying-pytorch-models-for-inference-at-scale-using-torchserve/</p>","tags":["Pre-trained Model"]},{"location":"blog/2020/07/deep-learning-computing-architecture/#diagram-of-ibm-max","title":"Diagram of IBM Max","text":"","tags":["Pre-trained Model"]},{"location":"blog/2020/07/tensorflowjs-poc-12-slim-based-on-facemesh/","title":"Tensorflow.js POC 12: Slim Based on Facemesh","text":"","tags":["Pre-trained Model"]},{"location":"blog/2020/07/tensorflowjs-poc-12-slim-based-on-facemesh/#overview","title":"Overview","text":"Figure 1 Computer Vision in AI","tags":["Pre-trained Model"]},{"location":"blog/2020/07/tensorflowjs-poc-10-tochup-based-on-facemesh/","title":"Tensorflow.js POC 10: Tochup Based on Facemesh","text":"","tags":["Pre-trained Model"]},{"location":"blog/2020/07/tensorflowjs-poc-10-tochup-based-on-facemesh/#overview","title":"Overview","text":"Figure 1 Computer Vision in AI","tags":["Pre-trained Model"]},{"location":"blog/2020/07/supervised-learning-vs-semi-supervised-learning-vs-reenforcement-learning/","title":"Supervised Learning vs. Semi-Supervised Learning vs. Reenforcement Learning","text":"<p>For deep learning, there are severals ways how the learning can be processed. Here we put a new tag on how a POC or a algorithm learning from the dataset with the 4 categories as below:</p>","tags":["Unsupervised Learning","Supervised Learning","Semi-Supervised Learning","Reinforcement Learning"]},{"location":"blog/2020/07/supervised-learning-vs-semi-supervised-learning-vs-reenforcement-learning/#unsupervised-learning","title":"Unsupervised Learning","text":"<ul> <li>Completely Unsupervised Phoneme Recognition by Adversarially Learning Mapping Relationships from Audio Embeddings</li> </ul>","tags":["Unsupervised Learning","Supervised Learning","Semi-Supervised Learning","Reinforcement Learning"]},{"location":"blog/2020/07/supervised-learning-vs-semi-supervised-learning-vs-reenforcement-learning/#supervised-learning","title":"Supervised Learning","text":"","tags":["Unsupervised Learning","Supervised Learning","Semi-Supervised Learning","Reinforcement Learning"]},{"location":"blog/2020/07/supervised-learning-vs-semi-supervised-learning-vs-reenforcement-learning/#semi-supervised-learning","title":"Semi-Supervised Learning","text":"","tags":["Unsupervised Learning","Supervised Learning","Semi-Supervised Learning","Reinforcement Learning"]},{"location":"blog/2020/07/supervised-learning-vs-semi-supervised-learning-vs-reenforcement-learning/#reinforcement-learning","title":"Reinforcement Learning","text":"","tags":["Unsupervised Learning","Supervised Learning","Semi-Supervised Learning","Reinforcement Learning"]},{"location":"blog/2020/07/supervised-learning-vs-semi-supervised-learning-vs-reenforcement-learning/#references","title":"References","text":"<ul> <li> <p>List of Top 5 Powerful Machine Learning Algorithms That Will Solve 99% of Your Problems</p> </li> <li> <p>Supervised Learning</p> </li> <li> <p>Are GAN's unsupervised or supervised?</p> </li> <li> <p>Cheat Sheets for AI, Neural Networks, Machine Learning, Deep Learning &amp; Big Data</p> </li> </ul>","tags":["Unsupervised Learning","Supervised Learning","Semi-Supervised Learning","Reinforcement Learning"]},{"location":"blog/2020/07/dataset/","title":"Dataset","text":"","tags":["Dataset"]},{"location":"blog/2020/07/dataset/#datasets","title":"Datasets","text":"","tags":["Dataset"]},{"location":"blog/2020/07/dataset/#datasets-for-faces","title":"Datasets for Faces","text":"<ul> <li>Chicago Face Dataset (CFD): CFD dataset</li> <li>Avataaars Library: Avataaars</li> <li>CUHK Face Sketch Database: CUFS</li> </ul>","tags":["Dataset"]},{"location":"blog/2020/07/dataset/#datasets-for-images","title":"Datasets for Images","text":"","tags":["Dataset"]},{"location":"blog/2020/07/dataset/#datasets-for-images-on-salient-object-detection","title":"Datasets for Images on Salient Object Detection","text":"<ul> <li>ECSSD</li> <li>CSSD</li> <li>DUTS-TE</li> <li>DUTS-TR</li> <li>salObj</li> <li>DUT-OMRON</li> <li> <p>- chimay SOD testset #1 </p> <ul> <li>Download from wget </li> </ul> <pre><code>wget -r -c -nH -np --cut-dirs=1 --content-disposition --no-check-certificate -U \"Mozilla/5.0 (Android) Nextcloud-android/3.8.0\" -O output.zip  http://dlc.barco.com:9980/s/m6dwLSan8M97YgW/download\n</code></pre> </li> </ul>","tags":["Dataset"]},{"location":"blog/2020/07/dataset/#datasets-for-audio","title":"Datasets for Audio","text":"<ul> <li>The Mozilla Common Voice (MCV)</li> <li>The UrbanSound8K dataset</li> </ul>","tags":["Dataset"]},{"location":"blog/2020/07/dataset/#datasets-for-wifi-locations","title":"Datasets for WIFI locations","text":"<ul> <li>WLAN/WiFi fingerprint</li> </ul>","tags":["Dataset"]},{"location":"blog/2020/07/dataset/#datasets-for-movie-rating","title":"Datasets for movie rating","text":"<ul> <li>MovieLens 100K Dataset</li> </ul>","tags":["Dataset"]},{"location":"blog/2020/07/dataset/#datasets-for-animations","title":"Datasets for animations","text":"<ul> <li>ghibli free download <ul> <li></li> <li>Download from wget  <pre><code>wget -r -c -nH -np --cut-dirs=1 --content-disposition --no-check-certificate -U \"Mozilla/5.0 (Android) Nextcloud-android/3.8.0\" -O output.zip  http://dlc.barco.com:9980/s/73XRwyGcwoSpKtM/download\n</code></pre></li> </ul> </li> <li> <p>\u8ffd\u756a\u5fc5\u5907\uff0c\u52a8\u6f2b\u89d2\u8272\u4e5f\u53ef\u4ee5\u7528\u4eba\u8138\u8bc6\u522b\u4e86</p> </li> <li> <p>Google Avatar Cartoon Set</p> </li> </ul>","tags":["Dataset"]},{"location":"blog/2020/07/dataset/#datasets-for-nlp","title":"Datasets for NLP","text":"<ul> <li> <p>Amazon Product Review Sentiment Labelled Sentences Data Set at UCI Machine Learning Repository.</p> <ul> <li></li> <li>Download from wget </li> </ul> <p><pre><code>wget -r -c -nH -np --cut-dirs=1 --content-disposition --no-check-certificate -U \"Mozilla/5.0 (Android) Nextcloud-android/3.8.0\" -O output.zip  http://dlc.barco.com:9980/s/B9BkniTf3LARbtL/download\n</code></pre> * Amazon product dataset</p> </li> </ul>","tags":["Dataset"]},{"location":"blog/2020/07/dataset/#references","title":"References","text":"<ul> <li>Google tensorflow dataset collections</li> <li>25 Open Datasets for Deep Learning Every Data Scientist Must Work With</li> <li>YouTube Faces DB</li> <li>Kaggle datasets</li> <li>Awesome Public Datasets</li> <li>GitHub\uff1aAnchor-free\u76ee\u6a19\u6aa2\u6e2c\u6700\u5168\u8cc7\u6599\u96c6\u9326</li> <li>UCI Sentiment Labelled Sentences Multilingual Data Set</li> </ul>","tags":["Dataset"]},{"location":"blog/2020/07/data-trasmit-over-sound--chimay-ultrasound/","title":"Data Trasmit Over Sound- Chimay Ultrasound","text":"","tags":["Audio Synthesis"]},{"location":"blog/2020/07/data-trasmit-over-sound--chimay-ultrasound/#references","title":"References","text":"<ul> <li>All patents related to Chirp</li> <li>Ultrasonic Communication Using Consumer Hardware</li> </ul>","tags":["Audio Synthesis"]},{"location":"blog/2020/08/pytorch-poc-2-opentts/","title":"Pytorch POC 2: OpenTTS","text":"Git Repo Status Progress Comments Pytorch POC #2 Pytorch POC #3 Pytorch POC #4 <p>Based on last time keyword spotting topics on Chimay, I even mention items about TTS (text-to-speech) and showed POCs. Here I adopt Opentts to create a API server for speech and later ultrasound generation from Web.</p> <p></p> <p>In live opentts demo site, you can check the conventional (non-deep learning) speech synthesis (marytts, nanotts) and deep-learning ones (Mozillatts with Tacotron and Tacotron2). Deep-learing ones provide a beeter speech quality. A public MOS test results as below also show similar conclusions.</p> <p></p> <p>Demo wave file as </p> <p></p> <p>Swagger API also includes the following:</p> <p></p> <p>The following diagram is from mozzila project. It shows the whole picture of nature lanaugege iteration with end users. But, of course, it will be a long way to go.</p> <p></p>","tags":["Pytorch","Pre-trained Model","Speech Synthesis","Supervised Learning"]},{"location":"blog/2020/08/pytorch-poc-2-opentts/#references","title":"References","text":"<ul> <li>Chimay Architecture for Keyword spotting</li> <li>Paper with code- speech synthesis</li> <li>Diagram of mozillatts- Tacotron and Tacotron2</li> <li>TSS systems and models</li> <li>How to build a voice assistant with open source Rasa and Mozilla tools</li> <li>The CMU Pronouncing Dictionary</li> <li>Build End-To-End TTS Tacotron: Griffin Lim \u4fe1\u53f7\u4f30\u8ba1\u7b97\u6cd5</li> <li>Mozilla \u7814\u7a76\uff1a\u6709\u4e9b\u6a5f\u5668\u5408\u6210\u8a9e\u97f3\u5df2\u7d93\u6bd4\u771f\u4eba\u8072\u97f3\u66f4\u6085\u8033</li> </ul>","tags":["Pytorch","Pre-trained Model","Speech Synthesis","Supervised Learning"]},{"location":"blog/2020/08/recommendation/","title":"Recommendation","text":"","tags":["Pytorch","Pre-trained Model","Recommendation","Supervised Learning"]},{"location":"blog/2020/08/recommendation/#overview","title":"Overview","text":"Figure 1 DataForecast in AI <p>pinreset and its pin alogirthm</p>","tags":["Pytorch","Pre-trained Model","Recommendation","Supervised Learning"]},{"location":"blog/2020/08/recommendation/#amplitude-based-recommendation","title":"Amplitude Based Recommendation","text":"","tags":["Pytorch","Pre-trained Model","Recommendation","Supervised Learning"]},{"location":"blog/2020/08/recommendation/#amplitude-user-cohort-lists","title":"amplitude user cohort lists","text":"<p>Here gives a demo for amplitude cohort download and query JSON-Server for Amplitude User Cohorts</p> <p></p>","tags":["Pytorch","Pre-trained Model","Recommendation","Supervised Learning"]},{"location":"blog/2020/08/recommendation/#references","title":"References","text":"<ul> <li>Netflix Recommendations: Beyond the 5 stars (Part 2)</li> <li>Building A Collaborative Filtering Recommender System with TensorFlow</li> <li>\u63a8\u85a6\u7cfb\u7d71\u548cTensorRec\u5165\u9580</li> <li>Boston ML - Architecting Recommender Systems</li> <li>\u7528Python\u9032\u884c\u5947\u7570\u503c\u5206\u89e3\uff08SVD\uff09\u5be6\u6230\u6307\u5357</li> <li>FIVE MOST POPULAR SIMILARITY MEASURES IMPLEMENTATION IN PYTHON</li> <li>Matrix Factorization- \u672c\u6587\u5c07\u901a\u904e\u4e00\u500b\u8a73\u7d30\u7684\u4f8b\u5b50\u5206\u6790\u77e9\u9663\u5206\u89e3\u601d\u60f3\u53ca\u5176\u5728\u63a8\u85a6\u7cfb\u7d71\u4e0a\u7684\u61c9\u7528</li> <li>Simple Content-based Recommendation Engine API With Flask [Heroku Deployed]</li> <li>Brief on Recommender Systems- Different types of recommendation methods used in industries</li> <li>Machine Learning for Recommender systems \u2014 Part 1 (algorithms, evaluation and cold start)</li> <li>Machine Learning for Recommender systems \u2014 Part 2 (Deep Recommendation, Sequence Prediction, AutoML and Reinforcement Learning in Recommendation)</li> <li>Recommendation System in Python: LightFM</li> <li>HYBRID RECOMMENDER SYSTEM BASED ON PERSONAL BEHAVIOR MINING</li> <li>Everything You Should Know about Auto-tagging Customer Feedback</li> <li>Compare Google Cloud Natural Language API, IBM Watson Studio, Microsoft Knowledge Exploration Service, and MonkeyLearn</li> <li>Complete Guide: How to use Grafana with a custom Node API</li> <li>use Grafana Infinity panel for connecting to REST API endpoints.</li> <li>Solving business usecases by recommender system using lightFM</li> </ul>","tags":["Pytorch","Pre-trained Model","Recommendation","Supervised Learning"]},{"location":"blog/2020/06/tensorflowjs-poc-12-cam-face-recognition-on-face-apijs/","title":"Tensorflow.js POC 12: Cam Face-recognition on face-api.js","text":"","tags":["Tensorflow","Pre-trained Model","Face Recognition","Reinforcement Learning"]},{"location":"blog/2020/06/tensorflowjs-poc-12-cam-face-recognition-on-face-apijs/#overview","title":"Overview","text":"Figure 1 Computer Vision in AI Git Repo Status Progress Comments tensorflow.js POC #11, #12","tags":["Tensorflow","Pre-trained Model","Face Recognition","Reinforcement Learning"]},{"location":"blog/2020/06/tensorflowjs-poc-12-cam-face-recognition-on-face-apijs/#what-is-reinforcement-learning","title":"What is reinforcement learning?","text":"","tags":["Tensorflow","Pre-trained Model","Face Recognition","Reinforcement Learning"]},{"location":"blog/2020/06/tensorflowjs-poc-12-cam-face-recognition-on-face-apijs/#goals-of-poc-12","title":"Goals of POC #12","text":"<ul> <li>Improve the POC #11 from semi-supervised learning to Reinforcement Learning by improve its face recognition rate</li> </ul>","tags":["Tensorflow","Pre-trained Model","Face Recognition","Reinforcement Learning"]},{"location":"blog/2020/06/tensorflowjs-poc-12-cam-face-recognition-on-face-apijs/#references","title":"References","text":"<ul> <li> <p>Attention-aware deep reinforcement learning for video face recognition</p> </li> <li> <p>180204 Attention-aware Deep Reinforcement Learning for Video Face Recognition</p> </li> </ul>","tags":["Tensorflow","Pre-trained Model","Face Recognition","Reinforcement Learning"]},{"location":"blog/2020/08/pytorch-poc-3-mozzilatts/","title":"Pytorch POC 3: MozzilaTTS","text":"Git Repo Status Progress Comments Pytorch POC #2 Pytorch POC #3 Pytorch POC #4","tags":["Pytorch","Pre-trained Model","Speech Synthesis","Supervised Learning"]},{"location":"blog/2020/08/pytorch-poc-3-mozzilatts/#references","title":"References","text":"<ul> <li>My settings for Mozilla/TTS Docker</li> </ul>","tags":["Pytorch","Pre-trained Model","Speech Synthesis","Supervised Learning"]},{"location":"blog/2020/08/deep-learning-computing-cicd-framework/","title":"Deep Learning Computing CI/CD Framework","text":""},{"location":"blog/2020/08/deep-learning-computing-cicd-framework/#overview","title":"Overview","text":"Figure 1 DevOps with AI"},{"location":"blog/2020/08/deep-learning-computing-cicd-framework/#pocs-on-small-changes-from-open-source","title":"POCs on Small changes from Open Source","text":"<ol> <li>Non-GPL license Open source projects are good basements to add value as POC espcially on Deep Learning areas.</li> </ol>"},{"location":"blog/2020/08/deep-learning-computing-cicd-framework/#pocs-on-short-but-full-cycle-deployments","title":"POCs on Short but Full Cycle Deployments","text":"<ol> <li> <p>Projects use git/yaml script to setup CI/CD pipeline and deployment flows.</p> </li> <li> <p>Easy to trasnfer from localhost to server via gitlab-runner</p> </li> </ol> <p></p> <p></p>"},{"location":"blog/2020/08/deep-learning-computing-cicd-framework/#deployments-based-on-dockerk8s-for-scalablity-portablity","title":"Deployments based on Docker/K8s for Scalablity, Portablity","text":"<ol> <li>Docker/K8s based deployment for scaiblity, portablity</li> </ol>"},{"location":"blog/2020/08/deep-learning-computing-cicd-framework/#all-pocs-setups-as-a-ecosystem","title":"All POCs setups as a Ecosystem","text":""},{"location":"blog/2020/08/deep-learning-computing-cicd-framework/#live-sites","title":"Live sites","text":""},{"location":"blog/2020/08/deep-learning-computing-cicd-framework/#gitlab-server","title":"Gitlab server","text":"Git Repo Status Progress Comments  User=root"},{"location":"blog/2020/08/deep-learning-computing-cicd-framework/#current-runners","title":"Current runners","text":"Servers OS Monitoring dlc Ubuntu18.04 dlc, ubuntu, GPU dlc1 Ubuntu18.04 dlc1, ubuntu, GPU dlc2 Ubuntu18.04 dlc2, ubuntu"},{"location":"blog/2020/08/deep-learning-computing-cicd-framework/#how-to-setup-dlcdlc1-to-run-a-tensorflow-gpu-project","title":"How to setup dlc/dlc1 to run a TensorFlow GPU project","text":""},{"location":"blog/2020/08/deep-learning-computing-cicd-framework/#with-gitlab-runner","title":"with Gitlab runner","text":""},{"location":"blog/2020/08/deep-learning-computing-cicd-framework/#step-1-add-project-to-gitlab-httpstailabdlccom9443deeplearningcomputing","title":"Step 1: Add project to Gitlab https://tailab.dlc.com:9443/deeplearningcomputing","text":""},{"location":"blog/2020/08/deep-learning-computing-cicd-framework/#step-15-if-your-project-is-in-httpsgitdlccom","title":"Step 1.5: If your project is in https://git.dlc.com/","text":"<p>You will need to import your project for gitlab CI/CD only by add your project into https://tailab.dlc.com:9443/root/git-sync-mirror. After that, bitbucket code will be automatically syced to gitlab server.</p>"},{"location":"blog/2020/08/deep-learning-computing-cicd-framework/#step-2-enable-dlc-gitlab-runner-and-setup-cicd","title":"Step 2: Enable dlc gitlab runner and setup CI/CD","text":""},{"location":"blog/2020/08/deep-learning-computing-cicd-framework/#step-3-see-the-cicd-results","title":"Step 3: See the CI/CD results","text":""},{"location":"blog/2020/08/deep-learning-computing-cicd-framework/#with-ssh-or-rdp-admin-account","title":"with ssh or RDP + admin account","text":"<p>Step 1: Check with wj.lee@dlc.com and ask for admin account of dlc</p> <p>Step 2: With ssh or RPD to login to dlc</p>"},{"location":"blog/2020/08/deep-learning-computing-cicd-framework/#how-to-setup-your-runner-how-to-install-gitlab-runner-in-your-ubuntu","title":"How to setup your runner- How to install gitlab-runner in your ubuntu","text":"<p>Step 1: </p> <pre><code>sudo curl -L --output /usr/local/bin/gitlab-runner https://gitlab-runner-downloads.s3.amazonaws.com/latest/binaries/gitlab-runner-linux-amd64\n</code></pre> <p>Step 2: </p> <p><pre><code>sudo chmod +x /usr/local/bin/gitlab-runner\n</code></pre> Step 3: </p> <pre><code>sudo useradd --comment 'GitLab Runner' --create-home gitlab-runner --shell /bin/bash\n</code></pre> <p>Step 4: </p> <p><pre><code>sudo gitlab-runner install --user=gitlab-runner --working-directory=/home/gitlab-runner\nsudo gitlab-runner start\n</code></pre> Step 5.0: Check https://docs.gitlab.com/runner/register/index.html</p> <p><pre><code>sudo gitlab-runner register\n</code></pre> and register interactively.</p> <p>or </p> <p>Step 5.1:</p> <p>First, by command line for docker gitlab-runner</p> <pre><code>sudo gitlab-runner register -n --url https://tailab.dlc.com:9443/ --registration-token YOUR-TOKEN --executor docker --description ${HOSTNAME}.dlc.com --tag-list \"ubuntu, docker, ${HOSTNAME}\" --run-untagged=\"true\" --docker-image \"docker:stable\" --docker-privileged --tls-ca-file=/etc/gitlab-runner/certs/ssl.csr \n</code></pre> <p>PS: YOUR-TOKEN can be obtained from Gitlab Server, in top menu, Admin Area-&gt;Runners to get the registration token. If you have no idea how to get '/etc/gitlab-runner/certs/ssl.csr', please check step XX.</p> <p>Second, by command line for shell gitlab-runner</p> <p><pre><code>sudo gitlab-runner register -n --url https://tailab.dlc.com:9443/ --registration-token YOUR-TOKEN --executor shell --description ${HOSTNAME}.dlc.com --tag-list \"ubuntu, shell, ${HOSTNAME}\" --run-untagged=\"true\" --tls-ca-file=/etc/gitlab-runner/certs/ssl.csr\n</code></pre> If you have no idea how to get '/etc/gitlab-runner/certs/ssl.csr', please check step XX.</p> <p>Step 6: Allow passwordless sudo</p> <p>execute  <pre><code>sudo joe /etc/sudoers\n</code></pre> , then check and edit/add one line as</p> <pre><code>gitlab-runner  ALL=(ALL) NOPASSWD: ALL\n</code></pre> <p>if no joe command, please install</p> <pre><code>sudo apt-get install joe\n</code></pre> <p>Step 6.1: Modify /etc/gitlab-runner/config.toml</p> <pre><code>sudo joe /etc/gitlab-runner/config.toml\n</code></pre> <p>and change concurrent from 1 to 40 or more. Also, for shell runner, please also add </p> <pre><code>environment = [\"GIT_SSL_NO_VERIFY=true\"]\n</code></pre> <p>Step 7: Install git-lsf</p> <pre><code>sudo apt-get -y install git-lfs\n</code></pre> <p>Step 8: Verify gitlab-runner <pre><code>sudo gitlab-runner verify\n</code></pre></p> <p>Step 9: </p> <p>For ubuntu 20.04, please do this to prevent Gitlab runner shell executor doesn't work on Ubuntu focal</p> <pre><code>sudo rm /home/gitlab-runner/.bash_logout\n</code></pre> <p>Step X: If you want to upgrade gitlab-runner</p> <p>This is optional step. If you want to upgrae gitlab-runner to newest one. Please do the following commands</p> <pre><code>sudo systemctl stop gitlab-runner.service\nsudo curl -L --output /usr/local/bin/gitlab-runner https://gitlab-runner-downloads.s3.amazonaws.com/latest/binaries/gitlab-runner-linux-amd64\nsudo systemctl start gitlab-runner.service\nsudo systemctl status gitlab-runner.service\n</code></pre> <p>Step XX: If you met the problem like below or you have no idea how to get '/etc/gitlab-runner/certs/ssl.csr' <pre><code>ERROR: Registering runner... failed\nrunner=CtzAuyzs status=couldn't execute POST against https://gitlab.test.com.tw/api/v4/runners: \nPost https://gitlab.test.com.tw/api/v4/runners: x509: certificate signed by unknown authority\nPANIC: Failed to register this runner. Perhaps you are having network problems \n</code></pre> then follow the steps below to get self-certification and note the filename is 'ssl.crt'</p> <p><pre><code>SERVER=SERVER=tailab.dlc.com\nPORT=9443\n\nCERTIFICATE=/etc/gitlab-runner/certs/ssl.crt\n\nsudo mkdir -p $(dirname \"$CERTIFICATE\")\n\nopenssl s_client -connect ${SERVER}:${PORT} -showcerts &lt;/dev/null 2&gt;/dev/null | sed -e '/-----BEGIN/,/-----END/!d' | sudo tee \"$CERTIFICATE\" &gt;/dev/null\n</code></pre> then you get '/etc/gitlab-runner/certs/ssl.crt' you need for gitlab-runner register.</p>"},{"location":"blog/2020/08/deep-learning-computing-cicd-framework/#references","title":"References","text":"<ul> <li>Even the Smallest Side Project Deserves its CI/CD Pipeline</li> <li>GitLab Auto DevOps \u6df1\u5165\u6dfa\u51fa\uff0c\u81ea\u52d5\u90e8\u7f72\uff0c\u9023\u8a2d\u5b9a\u6a94\u4e0d\u7528\uff1f\uff01</li> <li>Install Blackbox Exporter to Monitor Websites With Prometheus</li> <li>Adding Custom badges \ud83d\udcdb to Gitlab...</li> <li>Dynamic badges using shields.io</li> <li>Dynamic Badges with Shields.io and Runkit</li> <li>Markdown code for lots of small badges \ud83c\udf80 \ud83d\udccc (shields.io, forthebadge.com etc) \ud83d\ude0e</li> <li>Continuous Delivery for Machine Learning- Automating the end-to-end lifecycle of Machine Learning applications</li> <li>Welcome to The Hitchhiker\u2019s Guide to PlantUML!</li> <li>\u4f7f\u7528 OPENSSL \u7522\u751f SSL \u6191\u8b49\u9700\u8981\u7684 KEY \u8207 CSR</li> <li>OPENSSL\u5e38\u7528\u8a9e\u6cd5\u5f59\u6574</li> <li>[Linux] GitLab Runner \u8b49\u66f8\u932f\u8aa4\u8a3b\u518a\u5931\u6557 (x509: certificate signed by unknown authority)</li> </ul>"},{"location":"blog/2020/08/tensorflowjs-poc-13-handpose-and-its-potential-pocs/","title":"Tensorflow.js POC 13: Handpose and its potential POCs","text":"","tags":["Tensorflow","Pre-trained Model","Image Feature Extraction","Semi-Supervised Learning"]},{"location":"blog/2020/08/tensorflowjs-poc-13-handpose-and-its-potential-pocs/#overview","title":"Overview","text":"Figure 1 Computer Vision in AI Git Repo Status Progress Comments tensorflow.js POC #1- and WhoIsTalking for PIC #9.","tags":["Tensorflow","Pre-trained Model","Image Feature Extraction","Semi-Supervised Learning"]},{"location":"blog/2020/09/u2net/","title":"U2Net","text":"","tags":["Pytorch","Pre-trained Model","Image Segmentation","Supervised Learning"]},{"location":"blog/2020/09/u2net/#sod","title":"SOD","text":"<p>SOD (Salient Object Detection) is a topics in deep learning that by given a image, SOD can automatically segmentize the most interested objects of the image without any hints. SOD learns how human see the interested objects by detecting the denisity of feature points and segmentize the most dense parts. So far, U2Net provide a state of art performance.</p>","tags":["Pytorch","Pre-trained Model","Image Segmentation","Supervised Learning"]},{"location":"blog/2020/09/u2net/#first-results-of-u2net","title":"First results of U2Net","text":"<p>These are the first results of the U2Net on target benchmark images. For the full results can be checked in Chimay-SOD1 and asubset Chimay-SOD2 can be found.</p>    {% include ideal-image-slider/slider.html selector=\"slider1\" %}","tags":["Pytorch","Pre-trained Model","Image Segmentation","Supervised Learning"]},{"location":"blog/2020/09/u2net/#image-sliders","title":"Image sliders","text":"<p>In this page, image slider for jekyll and its js code is used for image slider.  Also a Jekyll Ideal Image Slider Include Demo shows the possiblity of Ideal Image Slider.</p>","tags":["Pytorch","Pre-trained Model","Image Segmentation","Supervised Learning"]},{"location":"blog/2020/09/u2net/#references","title":"References","text":"<ul> <li>\u90a3\u4e9b\u4e00\u9375\u6473\u5716\u7684\u8edf\u4ef6\u662f\u600e\u9ebc\u505a\u5230\u7684\uff1f\u9019\u4e9b\u8a9e\u7fa9\u5206\u5272\u65b9\u6cd5\u4e86\u89e3\u4e00\u4e0b</li> <li>\u986f\u8457\u6027\u6aa2\u6e2c\u6578\u64da\u96c6\u2014\u5b78\u7fd2\u7b46\u8a18</li> <li>Salient Object Detection</li> <li>awesome-segmentation-saliency-dataset</li> <li>Salient Objects Dataset (SOD)</li> <li>What are Autoencoders?</li> <li>[\u9b54\u6cd5\u9663\u7cfb\u5217] AutoEncoder \u4e4b\u8853\u5f0f\u89e3\u6790</li> <li>U2-Net: Going Deeper with Nested U-Structure for Salient Object Detection</li> </ul>","tags":["Pytorch","Pre-trained Model","Image Segmentation","Supervised Learning"]},{"location":"blog/2020/09/pytorch-poc-5-audio-de-noiser/","title":"Pytorch POC 5: Audio De-Noiser","text":"","tags":["Tensorflow","Pre-trained Model","Audio Synthesis","Supervised Learning"]},{"location":"blog/2020/09/pytorch-poc-5-audio-de-noiser/#overview","title":"Overview","text":"Figure 1 Computer Vision in AI <p>This project is interesting but still is in idea thinking phase.</p>","tags":["Tensorflow","Pre-trained Model","Audio Synthesis","Supervised Learning"]},{"location":"blog/2020/09/pytorch-poc-5-audio-de-noiser/#references","title":"References","text":"<ul> <li>How To Build a Deep Audio De-Noiser Using TensorFlow 2.0</li> </ul>","tags":["Tensorflow","Pre-trained Model","Audio Synthesis","Supervised Learning"]},{"location":"blog/2020/09/pytorch-poc-6-wifi-indoor-positioning/","title":"Pytorch POC 6: WIFI Indoor Positioning","text":"","tags":["Tensorflow","Fine-Tune Model","WIFI Indoor Positioning","Supervised Learning"]},{"location":"blog/2020/09/pytorch-poc-6-wifi-indoor-positioning/#project-map-of-dlc","title":"Project Map of DLC","text":"","tags":["Tensorflow","Fine-Tune Model","WIFI Indoor Positioning","Supervised Learning"]},{"location":"blog/2020/09/pytorch-poc-6-wifi-indoor-positioning/#overview","title":"Overview","text":"<p>This is still a very early stage of POC. With a pre-defined datasets, with many WIFI APP signal strengths data try to prdict the real location of the indoor room. </p> <p>This might be the first POC try to define our input and output data formats.</p> <p>Also, this POC also be a high level connector of several different components together since it will leaverage multi factor information to conclude a precise indoor locationing. </p> <p></p> <p></p> <p>When it comes to localization within buildings, a distinction can be made between client-based (Active tracking) and server-based positioning ( Passive tracking + Active tracking as optional). Client-based localization enables determining the position directly on the end user's device (e. g. smartphone). In the case of server-based localization, positioning takes place on a server.</p> <p></p>","tags":["Tensorflow","Fine-Tune Model","WIFI Indoor Positioning","Supervised Learning"]},{"location":"blog/2020/09/pytorch-poc-6-wifi-indoor-positioning/#technologies-for-client-based-indoor-positioning","title":"Technologies for Client-Based Indoor Positioning","text":"<p>Client-Based Indoor Positioning Compared: Wi-Fi vs. BLE vs. UWB vs. RFID vs. Ultrasound</p> <p></p> Technology Accuracy Range WIFI &lt;15m &lt;150m BLE 4 &lt;8m &lt;75m BLE 5.1 &lt;1m &lt;75m UWB &lt;30cm &lt;150m RFID Present detection only &lt;1m","tags":["Tensorflow","Fine-Tune Model","WIFI Indoor Positioning","Supervised Learning"]},{"location":"blog/2020/09/pytorch-poc-6-wifi-indoor-positioning/#technologies-for-server-based-indoor-positioning","title":"Technologies for Server-Based Indoor Positioning","text":"<p>Server-Based Indoor Positioning Compared: Wi-Fi vs. BLE vs. UWB vs. RFID vs. Ultrasound</p> <p></p> Technology Accuracy Range WIFI &lt;15m &lt;150m BLE 4 &lt;8m &lt;75m BLE 5.1 &lt;1m &lt;75m UWB &lt;30cm &lt;150m RFID Present detection only &lt;1m Ultrasound &lt;4m &lt;8m or Wall Indoor Positioning Technology Comments Client-Based No server setup. Use existing framework. but, low precision Server-Based (Passive tracking only) Server only. 3-5 sec delay. Not realtime application Server-Based (Passive+Active tracking) Need sever+client to get hybrid info for realtime &amp; stable location info","tags":["Tensorflow","Fine-Tune Model","WIFI Indoor Positioning","Supervised Learning"]},{"location":"blog/2020/09/pytorch-poc-6-wifi-indoor-positioning/#deeper-insights-of-client-based-indoor-positioning","title":"Deeper insights of Client-Based Indoor Positioning","text":"","tags":["Tensorflow","Fine-Tune Model","WIFI Indoor Positioning","Supervised Learning"]},{"location":"blog/2020/09/pytorch-poc-6-wifi-indoor-positioning/#indoor-positioning-use-cases","title":"Indoor Positioning Use Cases","text":"<p>Many different use cases.</p>","tags":["Tensorflow","Fine-Tune Model","WIFI Indoor Positioning","Supervised Learning"]},{"location":"blog/2020/09/pytorch-poc-6-wifi-indoor-positioning/#poc-using-find3","title":"POC using find3","text":"Git Repo Status Progress Comments Family=barco API:Devices by Loc (w 1 mins) <p>Get info of device='dlc2.barco.com' &amp; family='barco' from find3 server </p> <p><pre><code>curl -s -L -XGET \"http://dlc1.barco.com:8005/api/v1/location_basic/barco/dlc2.barco.com\"\n</code></pre> Get WIFI/BT SSID, BSSID, RSSID of the location and device</p> <pre><code>curl -XGET http://dlc1.barco.com:8005/api/v1/location/barco/dlc2.barco.com\n</code></pre> <p>Get all devices within 1 minsfrom family='barco' from find3 server and output it as a table</p> <p><pre><code>curl -s -L -XGET \"http://dlc1.barco.com:8005/api/v1/by_location/barco?history=1&amp;num_scanners=1\" | jq -s '.[] | .locations | .[] |.devices' | jsoncsv -A  | mkexcel | csvcut  -d , -C 5  |csvlook --snifflimit 0  | sudo tee output.txt\n</code></pre> Update GPS info of location 'Aris Cube' (device=dlc2.barco.com)</p> <p><pre><code>curl -s -L -XPOST \"http://dlc1.barco.com:8005/api/v1/gps\" -H \"Content-Type:application/json\" --data-binary '{\"f\":\"Barco\",\"l\":\"Aris Cube\",\"gps\":{\"lat\":25.01290,\"lon\":121.46701,\"alt\":0}}'\n</code></pre> Delete family=barco data (Dangersous operation!!! Warning!!!)</p> <pre><code> curl -s -L -XDELETE \"http://dlc1.barco.com:8005/api/v1/database/barco\"\n</code></pre>","tags":["Tensorflow","Fine-Tune Model","WIFI Indoor Positioning","Supervised Learning"]},{"location":"blog/2020/09/pytorch-poc-6-wifi-indoor-positioning/#block-diagram-of-find3","title":"Block diagram of find3","text":"Signal strength (dBm) Expected Quality -90 Chances of connecting are very low at this level -80 Unreliable signal strength -67 Reliable signal strength\u2013 the edge of what Cisco considers to be adequate to support Voice over WLAN -55 Anything down to this level can be considered excellent signal strength. -30 Maximum signal strength, you are probably standing right next to the access point.","tags":["Tensorflow","Fine-Tune Model","WIFI Indoor Positioning","Supervised Learning"]},{"location":"blog/2020/09/pytorch-poc-6-wifi-indoor-positioning/#a-snapshot-of-find3-active-rssi-its-bssid-ssid-on-20200831-nearby-dlc2barcocom","title":"A snapshot of find3 active RSSI &amp; its BSSID, SSID on 2020/08/31 nearby dlc2.barco.com","text":"Rssi Freq Type Algo Rate BSSID SSID -50 2.412 GHz 802.11n 6 12 E8  D0  FC  BF  18  0D ClickShare-Mobile-CX20 -52 5.825 GHz 802.11ac 7 8 04  D4  C4  D3  42  84 ASUS_Automation_5G -72 5.825 GHz 802.11ac 7 8 E4  AA  EA  58  43  93 CX-50-DEMO-RICHEN -50 2.457 GHz 802.11n 7 12 B0  7F  B9  82  03  04 NETGEAR25 -66 2.437 GHz 7 7 F0  1D  2D  5D  A9  C0 Barco -58 5.24 GHz 802.11n 6 8 28  24  FF  69  5B  B7 TestRoom_CSE800_mac (5GHz) -55 2.437 GHz 7 7 F0  1D  2D  5B  54  61 Barco Guest -61 5.24 GHz 802.11ac 1 8 3C  91  80  84  95  07 ClickShare-HW-UniSee -71 5.24 GHz 802.11ac 7 8 E4  AA  EA  35  04  65 ClickShare-1863551994 -55 2.437 GHz 802.11n 7 12 BE  42  4F  CB  C3  44 TestRoom-EAP-WinServer -46 5.785 GHz 6 8 7C  10  C9  61  97  84 TAI-QA-ASUSROG-6E_5G -49 5.18 GHz 802.11ac 7 8 10  63  C8  97  03  9F TAI_MR08 -58 5.785 GHz 802.11ac 7 8 BC  CF  4F  CB  C3  43 TestRoom-EAP -63 5.18 GHz 802.11ac 6 8 3C  91  80  84  9C  5D ClickShare-1862300001 -59 5.3 GHz 7 6 F0  1D  2D  5A  D5  6F Barco -57 2.412 GHz 802.11n 7 12 D4  6E  0E  41  61  EA keroro24 -60 5.32 GHz 9 6 F0  1D  2D  5B  54  6E Barco Guest -68 5.58 GHz 7 6 F0  1D  2D  5A  D9  8D BarcoIoT -55 5.18 GHz 802.11ac 7 8 3C  91  80  84  9C  5F TAI_MR09 -59 5.745 GHz 802.11ac 7 8 E4  AA  EA  74  46  FF ClickShare-Mobile-CX50 -53 2.412 GHz 7 7 F0  1D  2D  5A  D5  62 BarcoIoT -69 5.805 GHz 802.11ac 6 8 D4  6E  0E  41  61  E9 keroro5 -62 5.24 GHz 802.11ac 7 8 F8  A2  D6  6E  09  CF TestRoom_CSE200P_mac -58 5.785 GHz 802.11ac 7 8 BE  43  4F  CB  C3  45 TestRoom-EAP-WinServer -73 5.68 GHz 7 6 F0  1D  2D  5C  27  CF -39 2.447 GHz 802.11n 7 12 2C  FD  A1  CD  32  38 ASUS -69 5.765 GHz 802.11ac 7 8 70  2E  D9  42  F4  76 MAXHUB-6BF -56 5.745 GHz 802.11ac 7 8 E4  AA  EA  35  21  3F SClickShare-1863551600 -58 5.785 GHz 802.11ac 7 8 BE  43  4F  CB  C3  44 TestRoom-PSK2 -62 2.412 GHz 802.11n 7 12 E8  D0  FC  BF  13  5F ClickShare-1862300251 -59 5.18 GHz 802.11ac 7 8 E4  AA  EA  74  2C  D3 ClickShare-1863553421 -60 2.452 GHz 802.11n 7 12 04  D4  C4  35  69  E8 ASUS_SQA_JessicaHsu_2.4G -59 5.18 GHz 802.11ac 7 8 3C  91  80  84  95  D3 ClickShare-MR12 -69 2.412 GHz 1 7 F0  1D  2D  5A  D9  82 BarcoIoT -61 2.412 GHz 802.11n 7 12 BC  30  7E  F1  1D  9B ClickShare Audi-1 -61 5.18 GHz 802.11ac 7 8 3C  91  80  84  97  59 ClickShare-1862300078 -60 5.32 GHz 7 6 F0  1D  2D  5B  54  6F -78 2.437 GHz 802.11n 7 8 02  21  6A  F8  2F  AF DIRECT-ZWTAICLT24036msZe -62 5.24 GHz 802.11ac 1 8 02  12  5F  17  67  2F WiCS-2100-72E -59 2.462 GHz 802.11n 7 12 00  D0  41  DC  13  C8 myvita -55 5.18 GHz 802.11ac 7 8 3C  91  80  84  9F  25 ClickShare-0716174986 -71 5.18 GHz 802.11ac 7 8 10  63  C8  A7  9E  23 TAI_MR04 -86 5.18 GHz 802.11ac 1 8 10  63  C8  96  FF  87 TAI_MR01 -28 2.427 GHz 802.11n 1 12 7A  DA  88  B2  74  EC -66 2.422 GHz 802.11n 7 12 BC  30  7E  DD  3D  FE WiPG-1000-78C -56 5.18 GHz 802.11ac 7 8 F8  A2  D6  8D  BF  8F ClickShare-1863550102 -59 5.3 GHz 7 6 F0  1D  2D  5A  D5  6D BarcoIoT -73 5.24 GHz 802.11n 7 8 D8  61  62  8B  1D  EF TAI-MR06-Pingtung -52 5.18 GHz 802.11ac 7 8 12  63  C8  14  92  3B DIRECT-BM -83 5.68 GHz 7 6 F0  1D  2D  5A  CC  AE Barco Guest -81 5.26 GHz 7 6 F0  1D  2D  5D  B2  AF -68 2.437 GHz 802.11n 7 12 BC  EE  7B  7D  46  C0 -81 5.745 GHz 802.11ac 7 8 02  12  5F  17  68  8C WiCS-2100-88B -68 5.58 GHz 7 6 F0  1D  2D  5A  D9  8E Barco Guest -55 2.437 GHz 802.11n 1 12 BE  42  4F  CB  C3  43 TestRoom-PSK2 -77 5.745 GHz 802.11ac 7 8 02  12  5F  17  66  66 WiCS-2100-665 -52 5.18 GHz 802.11n 7 8 28  24  FF  4D  1B  FD ClickShare-1872075087 -82 5.2 GHz 802.11n 1 8 BC  30  7E  D9  C3  F4 ClickShare-8000000049 -72 5.18 GHz 802.11ac 7 8 E4  AA  EA  74  26  59 CX-50_Service -71 5.18 GHz 802.11ac 7 8 E8  D0  FC  BF  15  D1 Agile 01 -58 5.18 GHz 802.11ac 7 8 3C  91  80  84  95  B3 ClickShare-1862300131 -48 5.745 GHz 802.11ac 7 8 2C  FD  A1  CD  32  3C ASUS_5G -47 5.18 GHz 802.11ac 6 8 E4  AA  EA  58  45  8B ClickShare-1863552495 -84 5.22 GHz 802.11ac 7 8 3C  91  80  84  98  13 TAI_MR03 -69 5.18 GHz 802.11n 7 8 B8  B7  F1  01  B0  2D ClickShare-1873124000 -45 2.412 GHz 802.11n 1 12 C8  60  00  AC  FB  30 ASUS-FA -64 2.462 GHz 1 7 F0  1D  2D  5C  27  C0 -68 5.58 GHz 7 6 F0  1D  2D  5A  D9  8F Barco -54 2.412 GHz 7 7 F0  1D  2D  5A  D5  61 Barco Guest -64 5.745 GHz 802.11ac 7 8 02  12  5F  17  67  F2 WiCS-2100-LIN -53 5.2 GHz 802.11ac 9 8 04  D4  C4  35  69  EC ASUS_SQA_JessicaHsu_5G -64 2.462 GHz 7 7 F0  1D  2D  5C  27  C2 BarcoIoT -59 5.18 GHz 802.11ac 7 8 F8  A2  D6  8D  BF  5D ClickShare-1863550098 -81 5.745 GHz 802.11ac 7 8 02  12  5F  30  00  AC WiCS-2100-0AB -53 2.462 GHz 802.11n 7 12 00  4E  35  1A  C8  60 TAI-ClickShare-WPA2-DFS -73 5.68 GHz 9 6 F0  1D  2D  5C  27  CD BarcoIoT -59 5.18 GHz 802.11ac 7 8 F8  A2  D6  8D  CB  39 ClickShare-1863550140 -75 5.22 GHz 802.11n 7 8 28  24  FF  5B  05  05 CSE-200-demo -61 5.18 GHz 802.11ac 7 8 10  63  C8  BF  B1  81 ClickShare-1862337967 -80 5.26 GHz 7 6 F0  1D  2D  5D  B2  AE Barco Guest -53 5.18 GHz 802.11ac 1 8 A0  40  A0  82  49  0E QA-test-5G -51 2.412 GHz 802.11n 7 12 10  63  C8  96  F7  F3 ClickShare-T20 -60 5.32 GHz 7 6 F0  1D  2D  5B  54  6D BarcoIoT -43 5.22 GHz 7 8 6C  CD  D6  F5  9D  69 HW_WIFI6E_5G -52 2.462 GHz 802.11n 7 12 18  31  BF  C5  D1  38 SQA_Balloon_24G -82 5.68 GHz 7 6 F0  1D  2D  5A  CC  AF Barco -84 5.745 GHz 802.11ac 7 8 02  12  5F  30  06  4F WiCS-2100-64E -45 2.437 GHz 7 12 7C  10  C9  61  97  80 TAI-QA-ASUSROG-6E_2.4G -58 5.18 GHz 802.11ac 7 8 E4  AA  EA  58  43  81 ClickShare-1863552454 -75 5.5 GHz 7 6 F0  1D  2D  5D  A9  CD BarcoIoT -75 5.18 GHz 802.11ac 7 8 D8  F3  BC  54  4B  89 ClickShare-1862375851 -43 2.472 GHz 7 12 08  36  C9  2F  78  F5 TAI-QA-NetGear-2.4G -63 2.412 GHz 802.11n 7 12 3C  91  80  84  9C  91 ClickShare-1862300102 -68 2.412 GHz 6 7 F0  1D  2D  5A  D9  80 Barco -66 2.437 GHz 7 7 F0  1D  2D  5D  A9  C2 BarcoIoT -63 5.5 GHz 802.11ac 7 8 00  4E  35  1A  C8  70 TAI-ClickShare-WPA2-DFS","tags":["Tensorflow","Fine-Tune Model","WIFI Indoor Positioning","Supervised Learning"]},{"location":"blog/2020/09/pytorch-poc-6-wifi-indoor-positioning/#live-demo-of-find3-passive-rssi-of-dlc2barcocom","title":"Live demo of find3 passive RSSI of dlc2.barco.com","text":"","tags":["Tensorflow","Fine-Tune Model","WIFI Indoor Positioning","Supervised Learning"]},{"location":"blog/2020/09/pytorch-poc-6-wifi-indoor-positioning/#ppt","title":"PPT","text":"<p>Can't see the following page? Please login to MS office first.</p> This is an embedded Microsoft Office presentation, powered by Office.","tags":["Tensorflow","Fine-Tune Model","WIFI Indoor Positioning","Supervised Learning"]},{"location":"blog/2020/09/pytorch-poc-6-wifi-indoor-positioning/#references","title":"References","text":"<ul> <li>\u57fa\u4e8eWiFi\u6307\u7eb9\u7684\u5ba4\u5185\u5b9a\u4f4d (autoencoder)</li> <li>\u79fb\u52d5\u8a2d\u5099\u7a76\u7adf\u662f\u600e\u6a23\u50c5\u50c5\u4f7f\u7528Wi-Fi \u4f86\u5b9a\u4f4d\u7684?</li> <li>Wifi indoor positioning using Arduino and Machine Learning in 4 steps</li> <li>Fingerprinting Acoustic Localization Indoor Based on Cluster Analysis and Iterative Interpolation</li> <li>Learning the Localization Function: Machine Learning Approach to Fingerprinting Localization</li> <li>WiDeep: WiFi-based Accurate and Robust Indoor Localization System using Deep Learning</li> <li>UJIndoorLoc dataset download </li> <li>Wi-Fi- based Indoor Positioning System Using Smartphones</li> <li>[MQTT] Mosquitto Docker \u67b6\u8a2d\u8207\u8a2d\u5b9a\u8a73\u7d30\u904e\u7a0b</li> <li>\u5982\u4f55\u5728\u5bb6\u4e2d\u4efb\u4f55\u5730\u65b9\u6aa2\u67e5 Wi-Fi \u4fe1\u865f\u5f37\u5ea6</li> <li>iABACUS: A Wi-Fi-Based Automatic Bus Passenger counting System</li> <li>WIFI monitor mode- wiki</li> <li>WIFI Promiscuous mode- wifi</li> <li>wireshark</li> <li>Wireshark- Analyzing Wireless Packet Captures</li> <li>Scapy- Packet crafting for Python2 and Python3</li> </ul>","tags":["Tensorflow","Fine-Tune Model","WIFI Indoor Positioning","Supervised Learning"]},{"location":"blog/2020/09/tensorflowjs-poc-13-avatar-generator-with-face-apijs/","title":"Tensorflow.js POC 13: Avatar Generator with Face-API.js","text":"","tags":["Tensorflow","Fine-Tune Model","Face Recognition","Supervised Learning"]},{"location":"blog/2020/09/tensorflowjs-poc-13-avatar-generator-with-face-apijs/#overview","title":"Overview","text":"Figure 1 Computer Vision in AI","tags":["Tensorflow","Fine-Tune Model","Face Recognition","Supervised Learning"]},{"location":"blog/2020/09/tensorflowjs-poc-13-avatar-generator-with-face-apijs/#avatar-generator-with-face-apijs","title":"Avatar Generator with Face-API.js","text":"<p>This POC, a consequential POC of face-api.js, regonize the face from camera and find the nearest avatar from thousands avatars generated from avatar generators.</p>","tags":["Tensorflow","Fine-Tune Model","Face Recognition","Supervised Learning"]},{"location":"blog/2020/09/tensorflowjs-poc-13-avatar-generator-with-face-apijs/#references","title":"References","text":"<ul> <li>AWS Rekognition to create an Avatar</li> <li>Unsupervised Creation of Parameterized Avatars</li> <li>Generating custom photo-realistic faces using AI</li> <li>RoboCoDraw: Robotic Avatar Drawing with GAN-based Style Transfer and Time-efficient Path Optimization</li> <li>How to train a Tensorflow face object detection model</li> <li>TensorFlow 2 Object Detection API tutorial</li> <li>ghibli free download </li> <li>avataaars generator</li> <li>\u8fd9\u4e9b\u5ad4\u5983\u4e5f\u592a\u597d\u770b\u4e86\u5427\uff01AI\u590d\u539f\u300a\u5ef6\u79a7\u653b\u7565\u300b\u771f\u5b9e\u5386\u53f2\u4eba\u7269\uff0c\u539f\u6765\u201c\u786c\u6838\u5c11\u5973\u201d \u9b4f\u748e\u73de\u957f\u8fd9\u6837......</li> <li>\u5bb6\u91cc\u6ca1\u6709\u738b\u4f4d\u7ee7\u627f\uff1f\u6ca1\u5173\u7cfb\uff0c\u6709\u4eba\u7528AI\u6253\u9020\u4e86\u4e00\u4e2a\u7ae5\u8bdd\u9b54\u6cd5\u4e16\u754c</li> <li>\u535a\u58eb\u5f8c\u5c0f\u59d0\u59d0\u628a\u300c\u4e8c\u6b21\u5143\u8001\u5a46\u751f\u6210\u5668\u300d\u5347\u7d1a\u4e86\uff1a\u9019\u4e00\u6b21\u53ef\u4ee5\u6307\u5b9a\u756b\u98a8</li> <li>\u4e8c\u6b21\u5143\u59b9\u5b50\u4e94\u5b98\u756b\u98a8\u90fd\u80fd\u6539\uff0c\u5468\u535a\u78ca\u5718\u968a\u7528\u7121\u76e3\u7763\u65b9\u6cd5\u63a7\u5236GAN | CVPR 2021</li> </ul>","tags":["Tensorflow","Fine-Tune Model","Face Recognition","Supervised Learning"]},{"location":"blog/2020/08/deep-learning-computing-wiki/","title":"Deep Learning Computing wiki","text":""},{"location":"blog/2020/08/deep-learning-computing-wiki/#google-slides-presentation-in-a-jekyll-post","title":"Google Slides presentation in a Jekyll post","text":"<pre><code>&lt;style&gt;\n.responsive-wrap iframe{ max-width: 100%;}\n&lt;/style&gt;\n&lt;div class=\"responsive-wrap\"&gt;\n&lt;!-- this is the embed code provided by Google --&gt;\n  &lt;iframe src=\"https://docs.google.com/presentation/d/1F0DQTNPg3YG_By6LMGcgwT3icJ3eMhCiupAZm76CIfE/embed?start=false&amp;loop=false&amp;delayms=3000\" frameborder=\"0\" width=\"1024px\" height=\"768px\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\"&gt;&lt;/iframe&gt;\n&lt;!-- Google embed ends --&gt;\n&lt;/div&gt;\n</code></pre>"},{"location":"blog/2020/08/deep-learning-computing-wiki/#onedrive-powerpoint-presentation-in-a-jekyll-post","title":"Onedrive Powerpoint presentation in a Jekyll post","text":"<pre><code>&lt;style&gt;\n.responsive-wrap iframe{ max-width: 100%;}\n&lt;/style&gt;\n&lt;div class=\"responsive-wrap\"&gt;\n&lt;!-- this is the embed code provided by MS --&gt;\n&lt;iframe src=\"https://barcozone-my.sharepoint.com/personal/wj_lee_barco_com/_layouts/15/Doc.aspx?sourcedoc={565a0ed9-b548-42ad-9bcf-0c86c621c369}&amp;amp;action=embedview&amp;amp;wdAr=1.7777777777777777\" width=\"1024px\" height=\"768px\" frameborder=\"0\"&gt;This is an embedded &lt;a target=\"_blank\" href=\"https://office.com\"&gt;Microsoft Office&lt;/a&gt; presentation, powered by &lt;a target=\"_blank\" href=\"https://office.com/webapps\"&gt;Office&lt;/a&gt;.&lt;/iframe&gt;\n&lt;!-- MS embed ends --&gt;\n&lt;/div&gt;\n</code></pre>"},{"location":"blog/2020/08/deep-learning-computing-wiki/#references","title":"References","text":"<ul> <li>Jekyll Slides</li> <li>Jekyll Ideal Image Slider Include Demo</li> <li>The best MkDocs plugins and customizations</li> </ul>"},{"location":"blog/2020/08/deep-learning-computing-cicd-framework-ii/","title":"Deep Learning Computing CI/CD Framework (II)","text":""},{"location":"blog/2020/08/deep-learning-computing-cicd-framework-ii/#delete-all-non-running-pods","title":"Delete all non-running PODs","text":"<pre><code>kubectl get pod --all-namespaces | \\\nawk '{if ($4 != \"Running\") \\\nsystem (\"kubectl -n \" $1 \" delete pods \" $2  \" --grace-period=0 \" \" --force \")}'\n</code></pre>"},{"location":"blog/2020/08/deep-learning-computing-cicd-framework-ii/#references","title":"References","text":"<ul> <li>How To Install Kubernetes On Ubuntu 18.04</li> <li>How to Install and Configure Kubernetes (k8s) on Ubuntu 18.04 LTS</li> <li>\u5728 Kubernetes \u4e0a\u5b89\u88c5 Gitlab CI Runner</li> <li>How To Monitor Kubernetes With Prometheus</li> <li>kubernetes101-introduction-tutorial</li> <li>Kubernetes \u57fa\u790e\u6559\u5b78\uff08\u4e00\uff09\u539f\u7406\u4ecb\u7d39</li> <li>kubectl Cheat Sheet</li> <li>How To Access Kubernetes Dashboard Externally</li> <li>Kubernetes \u57fa\u790e\u6559\u5b78\uff08\u4e00\uff09\u539f\u7406\u4ecb\u7d39</li> <li>Kubernetes \u57fa\u790e\u6559\u5b78\uff08\u4e8c\uff09\u5be6\u4f5c\u7bc4\u4f8b\uff1aPod\u3001Service\u3001Deployment\u3001Ingress</li> <li>Kubernetes \u57fa\u790e\u6559\u5b78\uff08\u4e09\uff09Helm \u4ecb\u7d39\u8207\u5efa\u7acb Chart</li> <li>My Favorite CLI Tools</li> </ul>"},{"location":"blog/2021/02/customer-feedback-tagging-with-nlp/","title":"Customer Feedback Tagging with NLP","text":"","tags":["Pre-trained Model","NLP","Semi-Supervised Learning"]},{"location":"blog/2021/02/customer-feedback-tagging-with-nlp/#overview","title":"Overview","text":"Figure 1 Language Model in AI","tags":["Pre-trained Model","NLP","Semi-Supervised Learning"]},{"location":"blog/2021/02/customer-feedback-tagging-with-nlp/#project","title":"Project","text":"<p>With the data pipeline below to collect, pre-process, feature-engineer, NLP alogorithm applied to provide useful dashboard for analysis and further actions.</p> <p></p>","tags":["Pre-trained Model","NLP","Semi-Supervised Learning"]},{"location":"blog/2021/02/customer-feedback-tagging-with-nlp/#steps","title":"Steps","text":"","tags":["Pre-trained Model","NLP","Semi-Supervised Learning"]},{"location":"blog/2021/02/customer-feedback-tagging-with-nlp/#data-collection","title":"Data Collection:","text":"<p>Data mining or ETL (extract-transform-load) process to collect a corpus of unstructured data.</p>","tags":["Pre-trained Model","NLP","Semi-Supervised Learning"]},{"location":"blog/2021/02/customer-feedback-tagging-with-nlp/#data-preprocessing","title":"Data Preprocessing:","text":"<ul> <li> <p>Tokenization: Segmentation of running text into words.</p> </li> <li> <p>Lemmatization: Removal of inflectional endings to return the base form.</p> </li> <li> <p>Parts-of-speech tagging: Identification of words as nouns, verbs, adjectives etc.</p> </li> <li> <p>Lanaguage detection: Identification of the lanauges from single or several sentensces even a short one.</p> </li> </ul>","tags":["Pre-trained Model","NLP","Semi-Supervised Learning"]},{"location":"blog/2021/02/customer-feedback-tagging-with-nlp/#feature-engineering-nlp-visualization","title":"Feature Engineering (NLP visualization):","text":"<ul> <li> <p>Word Embeddings: Transforming text into a meaningful vector or array of numbers.</p> </li> <li> <p>N-grams: An unigram is a set of individual words within a document; bi-gram is a set of 2 adjacent words within a document.</p> </li> <li> <p>TF-IDF values: Term-Frequency-Inverse-Document-Frequency is a numerical statistic representing how important a word is to a document within a collection of documents.</p> </li> </ul>","tags":["Pre-trained Model","NLP","Semi-Supervised Learning"]},{"location":"blog/2021/02/customer-feedback-tagging-with-nlp/#application-of-nlp-algorithms","title":"Application of NLP Algorithms:","text":"<ul> <li> <p>Latent Dirichlet Allocation: Topic modeling algorithm for detecting abstract themes from a collection of documents.</p> </li> <li> <p>Support Vector Machine: Classification algorithm for detection of underlying consumer sentiment.</p> </li> <li> <p>Long Short-Term Memory Network: Type of recurrent neural networks for machine translation used in Google Translate.</p> </li> </ul> <p></p>","tags":["Pre-trained Model","NLP","Semi-Supervised Learning"]},{"location":"blog/2021/02/customer-feedback-tagging-with-nlp/#scope","title":"Scope","text":"<ul> <li>Topic Modeling:     How to automatically categorize customer complaints or intent classification?</li> </ul> <ul> <li>Sentiment analysis<ul> <li>How to detect sentiment from customer feedback, a complaint or a positive feedback?</li> <li>How to detect urgency?</li> </ul> </li> </ul>","tags":["Pre-trained Model","NLP","Semi-Supervised Learning"]},{"location":"blog/2021/02/customer-feedback-tagging-with-nlp/#implementation-winknlp","title":"Implementation: WinkNLP","text":"","tags":["Pre-trained Model","NLP","Semi-Supervised Learning"]},{"location":"blog/2021/02/customer-feedback-tagging-with-nlp/#customize-tagging-keyword","title":"Customize tagging keyword","text":"<ul> <li>What is wink-eng-lite-model?</li> <li>Custom Entities</li> <li>How to do sentiment analysis?</li> </ul>","tags":["Pre-trained Model","NLP","Semi-Supervised Learning"]},{"location":"blog/2021/02/customer-feedback-tagging-with-nlp/#implementation-spacy","title":"Implementation: spaCy","text":"","tags":["Pre-trained Model","NLP","Semi-Supervised Learning"]},{"location":"blog/2021/02/customer-feedback-tagging-with-nlp/#customize-tagging-keyword_1","title":"Customize tagging keyword","text":"<p>A high level view of generic model and the refine model in the whole process.</p> <p></p> <p>The detailed NLP refinement model is as below to improve the models of NER Tagging in spaCy model on user feedback.</p> <p>Another better idea is Active learning as below</p> <p></p> <p>and the whole data pipeline diagram for user feedback tagging is as below</p> <p></p>","tags":["Pre-trained Model","NLP","Semi-Supervised Learning"]},{"location":"blog/2021/02/customer-feedback-tagging-with-nlp/#references","title":"References","text":"<ul> <li>MonkeyLearn: How to Do Customer Complaint Classification with AI</li> <li>Humanizing Customer Complaints using NLP Algorithms</li> <li>Twitter Sentiment Analysis: A tale of Stream Processing</li> <li>9 Practical Tips for an Effective NPS Data Analysis and Reporting</li> <li>The right survey to measure each touchpoint of the customer journey</li> <li>Measuring Customer Experience Beyond NPS</li> <li>NLP visualizations for clear, immediate insights into text data and outputs</li> <li>Predicting happiness: user interactions and sentiment analysis in an online travel forum</li> <li>Analyzing Customer reviews using text mining to predict their behaviour</li> <li>Awesome Sentiment Analysis</li> <li>10 Popular Datasets For Sentiment Analysis</li> <li>\u4e2d\u6587\u60c5\u611f\u5206\u6790 (Sentiment Analysis) \u7684\u96be\u70b9\u5728\u54ea\uff1f\u73b0\u5728\u505a\u5f97\u6bd4\u8f83\u597d\u7684\u6709\u54ea\u51e0\u5bb6\uff1f</li> <li>Social Media Data for Sentiment Analysis</li> <li>Complete Guide: How to use Grafana with a custom Node API</li> <li>NATURAL LANGUAGE PROCESSINGNew AI Detects Sarcasm in Social Media</li> <li>Hubspot vs. Marketo: A Side-by-Side Comparison</li> <li>What Is Marketo? A Marketer's Guide</li> <li>Amplitude Recommend- Marketo / Amplitude Integration</li> <li>\u4f55\u8b02\u7cbe\u6e96\u884c\u92b7 Precision Marketing\uff1f\u7cbe\u6e96\u884c\u92b7\u601d\u7dad\u9032\u5316\u53f2\uff01</li> <li>NLP for Beginners: Cleaning &amp; Preprocessing Text Data</li> <li>Tutorial: Cleaning CSV Data Using the Command Line and csvkit</li> <li>csvkit: a Swiss Army Knife for CSV Data ?</li> <li>csvtk - A cross-platform, efficient and practical CSV/TSV toolkit</li> <li>Build better products and make better decisions with Iterate.</li> <li>How to Motivate Beta Testers to Give You Regular Product Feedback</li> <li>Chapter-2 AI Based Next best offer (Behaviour Driven Marketing and CDP)</li> <li>Benchmarking Language Detection for NLP</li> <li>A Complete Guide to Natural Language Processing (NLP)</li> <li>spaCy- Language Processing Pipelines</li> <li>How to Use AI in Excel for Automated Text Analysis</li> <li>The Complete Guide to Building a Chatbot with Deep Learning From Scratch</li> <li>\u9032\u5165 NLP \u4e16\u754c\u7684\u6700\u4f73\u6a4b\u6a11\uff1a\u5beb\u7d66\u6240\u6709\u4eba\u7684\u81ea\u7136\u8a9e\u8a00\u8655\u7406\u8207\u6df1\u5ea6\u5b78\u7fd2\u5165\u9580\u6307\u5357</li> <li>What are the Limitations of Automatic Image Annotation vs Manual?</li> <li>Cohort Analysis: An Insider Look at Your Customer's Behavior</li> <li>Amplitude Recommend- Analyze your predictive cohort</li> <li>Customer cohort analysis: Using event data to understand customer behavior</li> <li>Customer Cohort Analysis vs User Cohort Analysis: What\u2019s The Difference?</li> </ul>","tags":["Pre-trained Model","NLP","Semi-Supervised Learning"]},{"location":"blog/2021/02/customer-feedback-tagging-with-nlp/#spacy-ner","title":"spaCy NER","text":"<ul> <li>How to create training data for spaCy NER models using ipywidgets</li> <li>Training Spacy NER models with doccano</li> <li>NLP: Named Entity Recognition (NER) with Spacy and Python</li> <li>Prepare training data and train custom NER using Spacy Python</li> <li>Using spaCy 3.0 to build a custom NER model</li> <li>Extend Named Entity Recogniser (NER) to label new entities with spaCy</li> <li>How to Train NER with Custom training data using spaCy</li> <li>Building a custom Named Entity Recognition model using SpaCy</li> <li>tecoholic/ner-annotator Github</li> </ul>","tags":["Pre-trained Model","NLP","Semi-Supervised Learning"]},{"location":"blog/2021/02/customer-feedback-tagging-with-nlp/#nlp-kits","title":"NLP Kits","text":"<ul> <li>wink-js- GitHub</li> <li>nltk/nltk: NLTK Source - GitHub</li> <li>flairNLP/flair: A very simple framework for state-of-the-art Natural Language Processing (NLP)- GitHub</li> <li>Industrial Strength NLP- GitHub</li> <li>Tools for named entity recognition</li> <li>Introducing spaCy v3.0</li> <li>spaCy 3.0 demo</li> </ul>","tags":["Pre-trained Model","NLP","Semi-Supervised Learning"]},{"location":"blog/2021/02/customer-feedback-tagging-with-nlp/#label-annotation","title":"Label Annotation","text":"<ul> <li>The 5 Best Data Annotation Platforms &amp; Tools for Machine Learning (2021)</li> <li>heartexlabs/awesome-data-labeling- Github</li> <li>doccano/awesome-annotation-tools- Github</li> </ul>","tags":["Pre-trained Model","NLP","Semi-Supervised Learning"]},{"location":"blog/2021/02/customer-feedback-tagging-with-nlp/#ml-backend","title":"ML Backend","text":"<ul> <li>Predictive Maintenance with Deep Learning and Apache Flink</li> <li>Applying Machine Learning Models to InfluxDB with Loud ML &amp; Docker for Time Series Predictions</li> </ul>","tags":["Pre-trained Model","NLP","Semi-Supervised Learning"]},{"location":"blog/2021/04/aiot-data-collection/","title":"AIOT data collection","text":""},{"location":"blog/2021/04/aiot-data-collection/#aiot-data-collection","title":"AIOT data collection","text":"<p>AIOT is the combination of AI and IOT. Three major steps for AIOT: data, intelligence, actions mean data collection, smart data intelligence, then actions accordingly. For data collection, IOT devices events and user behaviorial events might be collected via several approaches. Here we focus on the approaches of data collections and aggreagration. </p>"},{"location":"blog/2021/04/aiot-data-collection/#via-influxdb","title":"via InfluxDB","text":"<p>Data collection, or IOT devices and user behaviorial events collection, can be formulated as time series or events and and stored in times series database (TSDB)</p> <p>a time series or event can be in the form of</p> <p><pre><code>measurement tag fields timestamp\n</code></pre> andd an example as <pre><code>temperature,device=device1,buidling=b1 internal=80,external=18 1443782126\n</code></pre></p> <p></p> <p>influxDB is the top solution for (TSDB) as collectors, aggregators and visualizer and its block digram as below.</p> <p></p> <p>A showcase of IOT data collection architecture via influxDB.</p> <p></p> <p></p> <p>A detailed pipeline for telegraf plugins: Inputs, outputs, processors plugins to process the data.</p> <p></p> <p>An example show how FLUX to handle the data source buckets, pipe, and  forward operator, and tables.</p> <pre><code>from(bucket:\"mongo\")\n  |&gt; range(start:-1h)\n  |&gt; filter(fn:(r) =&gt;\n    r._measurement == \"cpu\" and\n    r.cpu == \"cpu-total\"\n  )\n  |&gt; aggregateWindow(every: 1m, fn: mean)\n</code></pre>"},{"location":"blog/2021/04/aiot-data-collection/#references","title":"References","text":"<ul> <li>How To Install InfluxDB Telegraf and Grafana on Docker</li> <li>Nextcloud to influxDB (Grafana for display) with telegraf</li> <li>Cassandra vs. InfluxDB vs. MongoDB</li> <li>Flux Windowing and Aggregation</li> <li>GJSON PLAYGROUND</li> <li>influxdata/telegraf- HTTP Input Plugin</li> <li>IoT - Home sensor data monitoring with MQTT, InfluxDB and Grafana</li> </ul>"},{"location":"blog/2021/04/aiot-data-collection--part-2/","title":"AIOT data collection- Part 2","text":"<p>This post focuses on concepts of big data before go deeper of technology.</p>"},{"location":"blog/2021/04/aiot-data-collection--part-2/#bigger-picture-of-big-data","title":"Bigger picture of Big Data","text":"<p>Better service cycling from a deeper insights of data</p> <p></p> <p></p> <p>Deeper insights of data</p> <p></p> <p>Deeper insights of data: Coming from evolution of data analytics service</p> <p></p> <p>Deeper insights of data: Coming from more automation</p> <p></p> <p>\u0000</p>"},{"location":"blog/2021/04/3d-model-from-a-image/","title":"3D Model from A Image","text":""},{"location":"blog/2021/04/3d-model-from-a-image/#references","title":"References","text":"<ul> <li>crazytalk- talking avatar</li> <li>Headshot</li> <li>PIFuHD: Multi-Level Pixel-Aligned Implicit Function for High-Resolution 3D Human Digitization</li> <li>3D Face Reconstruction: Make a Realistic Avatar from a Photo</li> </ul>"},{"location":"blog/2021/05/tracking-vs-privacy/","title":"Tracking vs. Privacy","text":""},{"location":"blog/2021/05/tracking-vs-privacy/#references","title":"References","text":"<ul> <li>\u300a\u9078\u64c7\u540c\u610f(opt-in)\uff1f\u9078\u64c7\u9000\u51fa(opt-out)\uff1f\u4f01\u696d\u56e0\u61c9\u5169\u7a2e\u4e0d\u540c\u5236\u5ea6\u8a2d\u8a08\u6ce8\u610f\u4e8b\u9805\u300b\uff08\u53f0\u7063\uff09</li> </ul>"},{"location":"blog/2021/05/nlp--word-understanding/","title":"NLP- Word Understanding","text":"","tags":["NLP"]},{"location":"blog/2021/05/nlp--word-understanding/#overview","title":"Overview","text":"Figure 1 Language Model in AI <p>[![](https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F4440537%2Fa3a11ff3167936d62cfc8af32</p>","tags":["NLP"]},{"location":"blog/2021/05/deep-learning/","title":"Deep Learning","text":"","tags":["Deep Learning"]},{"location":"blog/2021/05/deep-learning/#data-engineer","title":"Data Engineer","text":"","tags":["Deep Learning"]},{"location":"blog/2021/05/deep-learning/#data-science","title":"Data Science","text":"","tags":["Deep Learning"]},{"location":"blog/2021/05/deep-learning/#machine-learning","title":"Machine Learning","text":"","tags":["Deep Learning"]},{"location":"blog/2021/05/deep-learning/#ai-ppts","title":"AI PPTs","text":"<p>This article collects excellent PPTs on AI.</p> <ul> <li>The future of AI- Lecun</li> </ul>","tags":["Deep Learning"]},{"location":"blog/2021/06/high-availablity-deployment/","title":"High Availablity Deployment","text":"","tags":["featured"]},{"location":"blog/2021/06/high-availablity-deployment/#ha-influxdb-in-dlctdc","title":"HA InfluxDB in dlc/TDC","text":"","tags":["featured"]},{"location":"blog/2021/06/high-availablity-deployment/#references","title":"References","text":"<ul> <li>docker\u4e0b\u7528keepalived+Haproxy\u5be6\u73fe\u9ad8\u53ef\u7528\u8ca0\u8f09\u5747\u8861\u53e2\u96c6</li> <li>[Day5] \u5be6\u73fe Kubernetes \u9ad8\u53ef\u9760\u67b6\u69cb\u90e8\u7f72</li> <li>HA InfluxDB as an external storage for Prometheus</li> <li>Monitoring a server cluster using Grafana and InfluxDB</li> <li>Installing InfluxDB with High Availability</li> <li>\u4f7f\u7528 Haproxy + Keepalived \u69cb\u5efa\u57fa\u65bc Docker \u7684\u9ad8\u53ef\u7528\u8ca0\u8f09\u5747\u8861\u670d\u52d9</li> <li>\u4f7f\u7528Influxdb-relay\u5b9e\u73b0Influxdb\u9ad8\u53ef\u7528\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000</li> </ul>","tags":["featured"]},{"location":"blog/2021/06/biz-needs-tech-alignment/","title":"Biz-Needs-Tech-Alignment","text":"<p>Technology must align with the goals of User needs and Businees Goals or it is just a works make things more complicated.</p> <p></p> <p>with this idea, you can work smarter, not harder. </p> <p>Technology mainly focus on system integration and its related components and output as Biz,Process (flow), Services, Products and etc. </p> <p>The component can be Algorithm, Application, Software, Hardware, System.</p> <p></p>"},{"location":"blog/2021/06/biz-needs-tech-alignment/#references","title":"References","text":""},{"location":"blog/2021/06/aiot-data-collection--part-3--web-scraper/","title":"AIOT data collection- Part 3- Web Scraper","text":""},{"location":"blog/2021/06/aiot-data-collection--part-3--web-scraper/#overview","title":"Overview","text":"Figure 1 DevOps with AI"},{"location":"blog/2021/06/aiot-data-collection--part-3--web-scraper/#refrences","title":"Refrences","text":"<ul> <li>8\u500b\u6700\u9ad8\u6548\u7684Python\u722c\u87f2\u6846\u67b6\uff0c\u4f60\u7528\u904e\u5e7e\u500b</li> <li>What web scraping tools are available?</li> <li>Github crawlab-team/crawlab- Comparison with Other Frameworks</li> </ul>"},{"location":"blog/2021/07/aiot-data-collection--part-4--alert/","title":"AIOT data collection- Part 4- Alert","text":""},{"location":"blog/2021/07/aiot-data-collection--part-4--alert/#overview","title":"Overview","text":"Figure 1 DevOps with AI"},{"location":"blog/2021/07/aiot-data-collection--part-4--alert/#alert-with-grafanainfluxdb","title":"Alert with Grafana/InfluxDB","text":"<p>The basic pipeline of grafana/prometheus/alertmanager/influxDB</p> <p></p> <p>The complete block diagram </p> <p></p>"},{"location":"blog/2021/07/aiot-data-collection--part-4--alert/#alert-event-trigger","title":"Alert Event Trigger","text":"<p>Related to alert event system, there are two questions, what events will trigger the alert (so called alert event trigger) and when context (so called alert event context) will show to user when alert.</p>"},{"location":"blog/2021/07/aiot-data-collection--part-4--alert/#refrences","title":"Refrences","text":""},{"location":"blog/2023/09/github-runner-in-synology-nas/","title":"Github runner in Synology NAS","text":"","tags":["Synology"]},{"location":"blog/2023/09/github-runner-in-synology-nas/#overview","title":"Overview","text":"Figure 1 DevOps with AI <ol> <li>Create YAMl file as below (it is a org github runner)</li> <li>In /volume1/docker/github-runner/data make sure remove .runner</li> <li>Generate docker with the new YAML and restart</li> </ol> <pre><code>version: '2.3'\nservices:\n  worker:\n    image: myoung34/github-runner:latest\n    container_name: GITHUB-RUNNER\n    restart: always\n    environment:\n      RUNNER_SCOPE: org\n      ORG_NAME: xxx\n      ACCESS_TOKEN: github_pat_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n      RUNNER_NAME: wenchiehlee.quickconnect.to\n      RUNNER_WORKDIR: /tmp/runner/work\n      RUNNER_GROUP: xxxx\n      RUNNER_ALLOW_RUNASROOT: true\n      DISABLE_AUTOMATIC_DEREGISTRATION: true\n      CONFIGURED_ACTIONS_RUNNER_FILES_DIR: /actions-runner-data # Required for persistence\n      LABELS: linux,x64,gpu,ubuntu-latest\n    security_opt:\n      # needed on SELinux systems to allow docker container to manage other docker containers\n      - label:disable\n    volumes:\n      - /volume1/docker/docker.sock:/var/run/docker.sock\n      - /volume1/docker/github-runner/tmp:/tmp:rw,Z\n      - /volume1/docker/github-runner/data:/actions-runner-data:rw,Z # required for persistence\n      - /volume1/web:/web:rw,Z\n      - /volume1/docker:/docker:rw,Z\n      - /volume1/homes:/homes:rw,Z\n      # note: a quirk of docker-in-docker is that this path\n      # needs to be the same path on host and inside the container,\n      # docker mgmt cmds run outside of docker but expect the paths from within\n</code></pre>","tags":["Synology"]},{"location":"blog/2023/09/github-runner-in-synology-nas/#refrences","title":"Refrences","text":"<ul> <li>Installing a Self-Hosted GitHub Actions Runner on Synology NAS</li> </ul>","tags":["Synology"]},{"location":"blog/2023/09/plantuml-styler/","title":"Plantuml-styler","text":""},{"location":"blog/2023/09/plantuml-styler/#overview","title":"Overview","text":"Figure 1 DevOps with AI"},{"location":"blog/2023/09/plantuml-styler/#refrences","title":"Refrences","text":"<ul> <li>isaaceindhoven/plantuml-styler</li> <li>The-Lum/puml-themes-gallery</li> <li>Plantuml Colors</li> <li>Ashley\u2019s PlantUML Documentation</li> </ul>"},{"location":"blog/2023/09/data-visualization/","title":"Data visualization","text":""},{"location":"blog/2023/09/data-visualization/#overview","title":"Overview","text":"Figure 1 DevOps with AI"},{"location":"blog/2023/09/data-visualization/#refrences","title":"Refrences","text":"<ul> <li>[Day 19] \u7121\u6cd5\u5206\u985e\u7684\u5176\u4ed6\u5716\u8868\u50111</li> <li>[Day 20] \u7121\u6cd5\u5206\u985e\u7684\u5176\u4ed6\u5716\u8868\u50112</li> </ul>"},{"location":"blog/2024/07/blog-with-jekyll-and-github-pages/","title":"Blog with Jekyll and Github pages","text":""},{"location":"blog/2024/07/blog-with-jekyll-and-github-pages/#overview","title":"Overview","text":"Figure 1 DevOps with AI <p>Recently, an excel data with many cells need to query from chatgpt and feed its response into the same table as an results. How can we have it based on current google framework? Please read and following this article to enable it..</p>"},{"location":"blog/2024/07/blog-with-jekyll-and-github-pages/#pre-requisites","title":"Pre-requisites","text":"<ul> <li>ChatGPT API Key</li> </ul>"},{"location":"blog/2024/07/blog-with-jekyll-and-github-pages/#refrences","title":"Refrences","text":"<ul> <li>How to Integrate ChatGPT with Google Sheets Using Google Apps Script</li> </ul>"},{"location":"blog/2024/07/raspberry-pi-with-github-actions-runner/","title":"Raspberry PI with github actions runner","text":""},{"location":"blog/2024/07/raspberry-pi-with-github-actions-runner/#overview","title":"Overview","text":"Figure 1 DevOps with AI"},{"location":"blog/2024/07/raspberry-pi-with-github-actions-runner/#dashboard-to-overview-the-runners","title":"Dashboard to overview the runners","text":""},{"location":"blog/2024/07/raspberry-pi-with-github-actions-runner/#raspberry-pi-5-to-enable-readwrite-google-sheet","title":"Raspberry PI 5 to enable read/write google sheet","text":""},{"location":"blog/2024/07/raspberry-pi-with-github-actions-runner/#raspberry-pi-to-get-self-hosted-runner-status-from-github-api","title":"Raspberry PI to get self-hosted runner status from github API","text":""},{"location":"blog/2024/07/raspberry-pi-with-github-actions-runner/#raspberry-pi-5-to-enable-camera","title":"Raspberry PI 5 to enable camera","text":"<pre><code>sudo apt install -y python3-picamera2\nsudo apt install -y python3-opencv\n</code></pre>"},{"location":"blog/2024/07/raspberry-pi-with-github-actions-runner/#refrences","title":"Refrences","text":"<ul> <li>RaspberryPi+Github Actions+CI/CD</li> <li>How we set up a production CI workflow with GitHub actions</li> <li>github awesome-raspberry-pi</li> <li>\u4f7f\u7528Python\u8b80\u5bebGoogle Sheet\uff1a\u8f15\u9b06\u7ba1\u7406\u8cc7\u6599\u7684\u6b65\u9a5f\u6307\u5357</li> <li>Th3Fire/Temp-SpreadSheet</li> <li>pygsheets - Using dotenv instead of json file</li> <li>Using secrets in GitHub Actions</li> <li>IMX219-170 Camera</li> </ul>"},{"location":"blog/2024/07/chatgpt-with-googlesheet-via-google-app-script/","title":"ChatGPT with GoogleSheet via Google app script","text":""},{"location":"blog/2024/07/chatgpt-with-googlesheet-via-google-app-script/#overview","title":"Overview","text":"<p>Recently, an excel data with many cells need to query from chatgpt and feed its response into the same table as an results. How can we have it based on current google framework? Please read and following this article to enable it..</p>"},{"location":"blog/2024/07/chatgpt-with-googlesheet-via-google-app-script/#pre-requisites","title":"Pre-requisites","text":"<ul> <li>ChatGPT API Key</li> </ul>"},{"location":"blog/2024/07/chatgpt-with-googlesheet-via-google-app-script/#refrences","title":"Refrences","text":"<ul> <li>How to Integrate ChatGPT with Google Sheets Using Google Apps Script</li> </ul>"},{"location":"blog/2024/07/data-centric-ai/","title":"Data centric AI","text":""},{"location":"blog/2024/07/data-centric-ai/#overview","title":"Overview","text":"Figure 1 DevOps with AI <p>In the traditional model-centric AI lifecycle, the focus is on finding better models to enhance performance, with data largely unchanged. This approach overlooks data quality issues like missing values, incorrect labels, and anomalies. Data-centric AI shifts the emphasis from models to systematic data engineering to build AI systems.</p> <p></p>"},{"location":"blog/2024/07/data-centric-ai/#refrences","title":"Refrences","text":"<ul> <li>Awesome-Data-Centric-AI</li> </ul>"},{"location":"blog/2024/07/","title":"2024/07","text":""},{"location":"blog/2023/09/","title":"2023/09","text":""},{"location":"blog/2021/07/","title":"2021/07","text":""},{"location":"blog/2021/06/","title":"2021/06","text":""},{"location":"blog/2021/05/","title":"2021/05","text":""},{"location":"blog/2021/04/","title":"2021/04","text":""},{"location":"blog/2021/02/","title":"2021/02","text":""},{"location":"blog/2020/09/","title":"2020/09","text":""},{"location":"blog/2020/08/","title":"2020/08","text":""},{"location":"blog/2020/07/","title":"2020/07","text":""},{"location":"blog/2020/06/","title":"2020/06","text":""},{"location":"blog/category/data/","title":"Data","text":""},{"location":"blog/category/devops/","title":"DevOps","text":""},{"location":"blog/category/iot/","title":"IOT","text":""},{"location":"blog/category/genai/","title":"GenAI","text":""},{"location":"blog/category/ai/","title":"AI","text":""},{"location":"blog/category/language-model/","title":"Language Model","text":""},{"location":"blog/category/3d/","title":"3D","text":""},{"location":"blog/category/computer-vision/","title":"Computer Vision","text":""},{"location":"blog/category/data-forecast/","title":"Data Forecast","text":""},{"location":"blog/page/2/","title":"Blogs","text":""},{"location":"blog/page/3/","title":"Blogs","text":""},{"location":"blog/page/4/","title":"Blogs","text":""},{"location":"blog/page/5/","title":"Blogs","text":""},{"location":"blog/category/ai/page/2/","title":"AI","text":""},{"location":"blog/category/ai/page/3/","title":"AI","text":""},{"location":"blog/category/computer-vision/page/2/","title":"Computer Vision","text":""},{"location":"tag/","title":"Tags","text":"<p>Tip</p> <p>Below is Tag lists</p>"},{"location":"tag/#audio-synthesis","title":"Audio Synthesis","text":"<ul> <li>Data Trasmit Over Sound- Chimay Ultrasound</li> <li>Pytorch POC 5: Audio De-Noiser</li> </ul>"},{"location":"tag/#dataset","title":"Dataset","text":"<ul> <li>Dataset</li> </ul>"},{"location":"tag/#deep-learning","title":"Deep Learning","text":"<ul> <li>Deep Learning</li> </ul>"},{"location":"tag/#face-recognition","title":"Face Recognition","text":"<ul> <li>Tensorflow.js POC 7: face-api.js</li> <li>Tensorflow.js POC 12: Cam Face-recognition on face-api.js</li> <li>Tensorflow.js POC 13: Avatar Generator with Face-API.js</li> </ul>"},{"location":"tag/#fine-tune-model","title":"Fine-Tune Model","text":"<ul> <li>Pytorch POC 6: WIFI Indoor Positioning</li> <li>Tensorflow.js POC 13: Avatar Generator with Face-API.js</li> </ul>"},{"location":"tag/#image-feature-extraction","title":"Image Feature Extraction","text":"<ul> <li>Tensorflow.js POC 4: Facemesh</li> <li>Tensorflow.js POC 1: Pose-animator</li> <li>Tensorflow.js POC 6: Posenet</li> <li>Tensorflow.js POC 9: WhoIsTalking Based on Facemesh</li> <li>Tensorflow.js POC 13: Handpose and its potential POCs</li> </ul>"},{"location":"tag/#image-segmentation","title":"Image Segmentation","text":"<ul> <li>Tensorflow.js POC 3: body-pixv2</li> <li>U2Net</li> </ul>"},{"location":"tag/#image-to-image-transformer","title":"Image to Image Transformer","text":"<ul> <li>Max POC 2: Super Resolution with SRGAN</li> <li>Tensorflow.js POC 8: Super Resolution with waifu2x</li> <li>Tensorflow.js POC 8: Super Resolution with waifu2x (II)</li> </ul>"},{"location":"tag/#nlp","title":"NLP","text":"<ul> <li>Customer Feedback Tagging with NLP</li> <li>NLP- Word Understanding</li> </ul>"},{"location":"tag/#pre-trained-model","title":"Pre-trained Model","text":"<ul> <li>Tensorflow.js POC 3: body-pixv2</li> <li>Tensorflow.js POC 4: Facemesh</li> <li>Tensorflow.js POC 1: Pose-animator</li> <li>Tensorflow.js POC 6: Posenet</li> <li>Tensorflow.js POC 9: WhoIsTalking Based on Facemesh</li> <li>Max POC 2: Super Resolution with SRGAN</li> <li>Tensorflow.js POC 8: Super Resolution with waifu2x</li> <li>Tensorflow.js POC 8: Super Resolution with waifu2x (II)</li> <li>Tensorflow.js POC 7: face-api.js</li> <li>Pre-trained Model, and What is Next Steps</li> <li>Deep Learning Computing Architecture</li> <li>Tensorflow.js POC 12: Slim Based on Facemesh</li> <li>Tensorflow.js POC 10: Tochup Based on Facemesh</li> <li>Pytorch POC 2: OpenTTS</li> <li>Recommendation</li> <li>Tensorflow.js POC 12: Cam Face-recognition on face-api.js</li> <li>Pytorch POC 3: MozzilaTTS</li> <li>Tensorflow.js POC 13: Handpose and its potential POCs</li> <li>U2Net</li> <li>Pytorch POC 5: Audio De-Noiser</li> <li>Customer Feedback Tagging with NLP</li> </ul>"},{"location":"tag/#pytorch","title":"Pytorch","text":"<ul> <li>Pytorch POC 2: OpenTTS</li> <li>Recommendation</li> <li>Pytorch POC 3: MozzilaTTS</li> <li>U2Net</li> </ul>"},{"location":"tag/#recommendation","title":"Recommendation","text":"<ul> <li>Recommendation</li> </ul>"},{"location":"tag/#reinforcement-learning","title":"Reinforcement Learning","text":"<ul> <li>Supervised Learning vs. Semi-Supervised Learning vs. Reenforcement Learning</li> <li>Tensorflow.js POC 12: Cam Face-recognition on face-api.js</li> </ul>"},{"location":"tag/#semi-supervised-learning","title":"Semi-Supervised Learning","text":"<ul> <li>Tensorflow.js POC 7: face-api.js</li> <li>Supervised Learning vs. Semi-Supervised Learning vs. Reenforcement Learning</li> <li>Tensorflow.js POC 13: Handpose and its potential POCs</li> <li>Customer Feedback Tagging with NLP</li> </ul>"},{"location":"tag/#speech-synthesis","title":"Speech Synthesis","text":"<ul> <li>Pytorch POC 2: OpenTTS</li> <li>Pytorch POC 3: MozzilaTTS</li> </ul>"},{"location":"tag/#supervised-learning","title":"Supervised Learning","text":"<ul> <li>Tensorflow.js POC 3: body-pixv2</li> <li>Tensorflow.js POC 4: Facemesh</li> <li>Tensorflow.js POC 1: Pose-animator</li> <li>Tensorflow.js POC 6: Posenet</li> <li>Tensorflow.js POC 9: WhoIsTalking Based on Facemesh</li> <li>Supervised Learning vs. Semi-Supervised Learning vs. Reenforcement Learning</li> <li>Pytorch POC 2: OpenTTS</li> <li>Recommendation</li> <li>Pytorch POC 3: MozzilaTTS</li> <li>U2Net</li> <li>Pytorch POC 5: Audio De-Noiser</li> <li>Pytorch POC 6: WIFI Indoor Positioning</li> <li>Tensorflow.js POC 13: Avatar Generator with Face-API.js</li> </ul>"},{"location":"tag/#synology","title":"Synology","text":"<ul> <li>Github runner in Synology NAS</li> </ul>"},{"location":"tag/#tensorflow","title":"Tensorflow","text":"<ul> <li>Tensorflow.js POC 3: body-pixv2</li> <li>Tensorflow.js POC 4: Facemesh</li> <li>Tensorflow.js POC 1: Pose-animator</li> <li>Tensorflow.js POC 6: Posenet</li> <li>Tensorflow.js POC 9: WhoIsTalking Based on Facemesh</li> <li>Tensorflow.js POC 8: Super Resolution with waifu2x</li> <li>Tensorflow.js POC 8: Super Resolution with waifu2x (II)</li> <li>Tensorflow.js POC 7: face-api.js</li> <li>Tensorflow.js POC 12: Cam Face-recognition on face-api.js</li> <li>Tensorflow.js POC 13: Handpose and its potential POCs</li> <li>Pytorch POC 5: Audio De-Noiser</li> <li>Pytorch POC 6: WIFI Indoor Positioning</li> <li>Tensorflow.js POC 13: Avatar Generator with Face-API.js</li> </ul>"},{"location":"tag/#unsupervised-learning","title":"Unsupervised Learning","text":"<ul> <li>Supervised Learning vs. Semi-Supervised Learning vs. Reenforcement Learning</li> </ul>"},{"location":"tag/#wifi-indoor-positioning","title":"WIFI Indoor Positioning","text":"<ul> <li>Pytorch POC 6: WIFI Indoor Positioning</li> </ul>"},{"location":"tag/#featured","title":"featured","text":"<ul> <li>High Availablity Deployment</li> </ul>"}]}